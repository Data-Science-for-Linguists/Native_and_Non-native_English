# Report 1 (Project Plan)
## 10/3/2017
I found a corpus of English conversations between nonnative speakers, called the Vienna-Oxford International Corpus of English. My next steps will include
1. Finding a corpus of conversations between native English speakers.
2. Beginning to process the corpus/read the files. This step could take some time, since the Vienna-Oxford International Corpus contains markdown files. I will also probably have to reformat the data.

# Report 2 (First Progress Report)
## 10/12/2017
I used BeautifulSoup to process the XML files in the Vienna-Oxford corpus. Reading and manipulating the data didn't take as much time or work as I originally expected, but it did take some time to get used to the BeautifulSoup commands. I think that, as of now, my organization of the data is pretty good, but I am expecting to modify it later on as my goals become more clear.
Even though the Vienna-Oxford corpus focuses on non-native speakers, some of the participants listed in the corpus do speak English as a native language. One of the statistics that I found was the number of participants who have English listed as an L1. While the proportion of native English speakers was small, there were more than I expected. Originally, I was planning on finding an additional corpus of native English to compare to the Vienna-Oxford corpus; however, now I'm considering removing all of the native English speakers from the Vienna-Oxford corpus, and creating a new corpus from their speech. I think that the main advantage of creating this new corpus is consistency. To compare native and non-native speakers, I would have to find another corpus with a similar annotation system, which could be difficult. If I create this new corpus, the native speech and nonnative speech would come from the same corpus and have the same annotations, making the comparisons much more feasible. However, since the nonnative speakers vastly outnumber the native speakers, the native corpus would be much smaller than the nonnative corpus, which isn't ideal.

# Report 3
## 10/31/2017
I looked into the distribution of dialects among the native speakers in the VOICE corpus, and the majority spoke British English. I downloaded the British National Corpus, and I plan on comparing it to the entries in the Vienna-Oxford Corpus of International English. About 90% of the files in the BNC are from written sources, and the other 10% are transcripts of speech. I had to spend a decent amount of time writing code to show which files are speech and which are written. The speech transcripts contain an "stext" tag, which encases all of the speech in the file. The written files do not have this tag. To distinguish between the two types, I check each file for the tag. After I determined which files came from written sources, I deleted them since I won't need them and they took up a lot of space. Each word in the BNC is tagged with its part of speech tag and lemma. I also noticed that the VOICE corpus has a part-of-speech tagged file, so part of speech tags could be interestng to use.

# Report 4
## 11/2/2017 (Second Progress Report)
I created two files to process the two corpora, and I think that I finalized my data organization. The corpora are organized in nested dictionaries, and each corpora has two dictionaries: one for tokenized words and the other for lists of (word, part-of-speech tag) tuples. I'm still not completely comfortable with BeautifulSoup, and I did run into issues with it, so this step took much longer than I expected it to. Even though I think that my data organization is practically finalized, I may go back and modify the data later on. For example, the two corpora use different tag sets, which isn't very useful if I want to compare them. So I could look into the two tag sets more closely and try to convert the tags of one (or both) of the corpora so they match. Another thing I was think of looking into was whether the participants' speech changed when they were conversing with native speakers. To do this, I would probably have to create a dictionary that has each conversation to the total participants and the number of participants who are native speakers. When I finished these steps, I performed some very basic analyses on the corpora. I looked at the average utterance length, common words, bigrams, and stop words. While there were a few things that caught my attention from these analyses, I didn't notice any major differences between the two corpora. In addition to looking at other features, I plan on further investigating words and bigrams, since I think that there probably are significant differences that aren't clear at first glance. I also plan on looking into differences in L1 groups in the VOICE corpus, and I think that bigrams could be very useful here.

# Report 5
## 11/17/2017
Since the license for the BNC is very restrictive, I talked to Lauren Collister today to see what my options are in terms of sharing the data. Even though BNC's license forbids copying or redistributing the corpus to others, she told me that, because of Fair Use, that I could probably display some small parts of the corpus throughout my code. I will not be able to share the entire corpus with everyone, but I do plan on showing small segments of the data and statistics about the data through my code.

# Report 6
## 11/26/2017
I made some changes to my code that processes the VOICE data. First, I wrote code that creates a pickle file of the dictionary containing the participant information. This will be useful when I analyze the data, since it will allow me to easily access VOICE participants' native languages. I also created a new dictionary containing information about each corpus in VOICE. This dictionary contains the total number of participants, the total number of native speakers, and the total number of non-native speakers for each conversation. This would be useful if I decide to look into whether non-native participants' speech changed when they were around native speakers. 
I also started setting up the data to do more in depth analysis of bigrams.

# Report 7
## 11/28/2017 (Third Progress Report)
I managed to compare the bigrams in VOICE and BNC, in addition to hesitations between participants in the two groups. When I compared the bigrams, I found that repeated words and bigrams containing 'er' and 'erm' were much more common in VOICE (non-native speakers) than they were in BNC (native speakers). Another interesting pattern that I noticed was that contractions (e.g. can't, won't) were much more common in BNC than they were in VOICE. Contractions were about twice as common in the BNC as they were in VOICE, and there was a larger variety of contractions used among BNC's most common bigrams than there were among VOICE's most common bigrams. In addition, I applied the same comparisons to subgroups of Germanic, Romance, and Slavic language speakers. The Germanic language speakers had slightly more bigrams in common with the BNC than the other two L1 groups, and the Romance language speakers tended to use contractions much more frequently than speakers in the other two groups did. I also spent some time looking into hesitations between the native and non-native speakers. One of the features I considered was repeating a single word, which could indicate stuttering or some form of hesitation. I found that nonnative speakers were significantly more likely to repeat words than native speakers. 
My next step will be to create graphs and plots that I can use in my presentation later this week. In terms of analysis, I plan on comparing a few L1s from VOICE. I may use the same comparisons that I discussed above, but since all of these utterances will come from the same corpus, I think I may also leverage the part of speech tags to see if any of the L1 groups tend to use any specific patterns. Depending on how much I can do after that, I may try some maching learning algorithms using differentiating features that I discover in the analysis. I may also look at whether nonnative speakers' speech changes when they converse with native speakers.