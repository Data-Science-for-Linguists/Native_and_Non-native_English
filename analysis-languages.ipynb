{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_tokenized.p', 'rb')\n",
    "VOICE_toks = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_tagged.p', 'rb')\n",
    "VOICE_tags = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_native_tagged.p', 'rb')\n",
    "VOICE_native_tags = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_participant_info.p', 'rb')\n",
    "participants = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_monolingual_speakers(participant_dict, language):\n",
    "    speakers = []\n",
    "    for p in participant_dict.keys():\n",
    "        L1s = participant_dict[p]['L1']\n",
    "        if(len(L1s) == 1 and language in L1s):\n",
    "            speakers.append(p)\n",
    "            \n",
    "    return speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_speakers = get_monolingual_speakers(participants, 'eng')\n",
    "pol_speakers = get_monolingual_speakers(participants, 'pol')\n",
    "kor_speakers = get_monolingual_speakers(participants, 'kor')\n",
    "fin_speakers = get_monolingual_speakers(participants, 'fin')\n",
    "dan_speakers = get_monolingual_speakers(participants, 'dan')\n",
    "tur_speakers = get_monolingual_speakers(participants, 'tur')\n",
    "hun_speakers = get_monolingual_speakers(participants, 'hun')\n",
    "por_speakers = get_monolingual_speakers(participants, 'por')\n",
    "rus_speakers = get_monolingual_speakers(participants, 'rus')\n",
    "mlt_speakers = get_monolingual_speakers(participants, 'mlt')\n",
    "lav_speakers = get_monolingual_speakers(participants, 'lav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English speakers: 62\n",
      "Polish speakers: 35\n",
      "Korean speakers: 14\n",
      "Finnish speakers: 51\n",
      "Danish speakers: 35\n",
      "Turkish speakers: 14\n",
      "Hungarian speakers: 13\n",
      "Portuguese speakers: 21\n",
      "Russian speakers: 22\n",
      "Maltese speakers: 22\n",
      "Latvian speakers: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"English speakers:\", len(eng_speakers))\n",
    "print(\"Polish speakers:\", len(pol_speakers))\n",
    "print(\"Korean speakers:\", len(kor_speakers))\n",
    "print(\"Finnish speakers:\", len(fin_speakers))\n",
    "print(\"Danish speakers:\", len(dan_speakers))\n",
    "print(\"Turkish speakers:\", len(tur_speakers))\n",
    "print(\"Hungarian speakers:\", len(hun_speakers))\n",
    "print(\"Portuguese speakers:\", len(por_speakers))\n",
    "print(\"Russian speakers:\", len(rus_speakers))\n",
    "print(\"Maltese speakers:\", len(mlt_speakers))\n",
    "print(\"Latvian speakers:\", len(lav_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to use English\n",
    "#Use Korean, Finnish, Turkish\n",
    "#Danish, Portuguese, Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of speakers\n",
    "def get_tagged_utterances(tokens, speakers): \n",
    "    utterances = []\n",
    "    for conversation in tokens.keys():\n",
    "        for pair in tokens[conversation]:\n",
    "            if(pair[1] in speakers):\n",
    "                utterances.append(tokens[conversation][pair])\n",
    "                \n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_speech = get_tagged_utterances(VOICE_native_tags, eng_speakers)\n",
    "kor_speech = get_tagged_utterances(VOICE_tags, kor_speakers)\n",
    "fin_speech = get_tagged_utterances(VOICE_tags, fin_speakers)\n",
    "tur_speech = get_tagged_utterances(VOICE_tags, tur_speakers)\n",
    "dan_speech = get_tagged_utterances(VOICE_tags, dan_speakers)\n",
    "por_speech = get_tagged_utterances(VOICE_tags, por_speakers)\n",
    "pol_speech = get_tagged_utterances(VOICE_tags, pol_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(li):\n",
    "    tokens = []\n",
    "    for u in li:\n",
    "        for w in u:\n",
    "            tokens.append(w)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_tags(li):\n",
    "    unwanted_tags = [\"BRfBR\", \"PAfPA\", \"UHfUH\", \"UNIfUNI\", \"UNKfNN\", \"LAfLA\", \"XXfXX\"]\n",
    "    return [pair for pair in li if pair[1] not in unwanted_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(li):\n",
    "    return[pair[1] for pair in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_toks = get_pairs(eng_speech)\n",
    "eng_toks = remove_tags(eng_toks)\n",
    "eng_tags = get_tags(eng_toks)\n",
    "\n",
    "kor_toks = get_pairs(kor_speech)\n",
    "kor_toks = remove_tags(kor_toks)\n",
    "kor_tags = get_tags(kor_toks)\n",
    "\n",
    "fin_toks = get_pairs(fin_speech)\n",
    "fin_toks = remove_tags(fin_toks)\n",
    "fin_tags = get_tags(fin_toks)\n",
    "\n",
    "tur_toks = get_pairs(tur_speech)\n",
    "tur_toks = remove_tags(tur_toks)\n",
    "tur_tags = get_tags(tur_toks)\n",
    "\n",
    "dan_toks = get_pairs(dan_speech)\n",
    "dan_toks = remove_tags(dan_toks)\n",
    "dan_tags = get_tags(dan_toks)\n",
    "\n",
    "por_toks = get_pairs(por_speech)\n",
    "por_toks = remove_tags(por_toks)\n",
    "por_tags = get_tags(por_toks)\n",
    "\n",
    "pol_toks = get_pairs(pol_speech)\n",
    "pol_toks = remove_tags(pol_toks)\n",
    "pol_tags = get_tags(pol_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigrams(li):\n",
    "    trigram_list = []\n",
    "    for trigram in list(nltk.trigrams(li)):\n",
    "        if len(trigram) > 0:\n",
    "            trigram_list.append(trigram)\n",
    "            \n",
    "    return trigram_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tag_trigrams = get_trigrams(eng_tags)\n",
    "kor_tag_trigrams = get_trigrams(kor_tags)\n",
    "fin_tag_trigrams = get_trigrams(fin_tags)\n",
    "tur_tag_trigrams = get_trigrams(tur_tags)\n",
    "dan_tag_trigrams = get_trigrams(dan_tags)\n",
    "por_tag_trigrams = get_trigrams(por_tags)\n",
    "pol_tag_trigrams = get_trigrams(pol_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47990"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_tag_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common part-of-speech trigrams in Engish. Compare with these frequencies with other L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_freq = nltk.FreqDist(eng_tag_trigrams)\n",
    "kor_freq = nltk.FreqDist(kor_tag_trigrams)\n",
    "fin_freq = nltk.FreqDist(fin_tag_trigrams)\n",
    "tur_freq = nltk.FreqDist(tur_tag_trigrams)\n",
    "dan_freq = nltk.FreqDist(dan_tag_trigrams)\n",
    "por_freq = nltk.FreqDist(por_tag_trigrams)\n",
    "pol_freq = nltk.FreqDist(pol_tag_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('INfIN', 'DTfDT', 'NNfNN'), 719),\n",
       " (('DTfDT', 'NNfNN', 'INfIN'), 580),\n",
       " (('DTfDT', 'JJfJJ', 'NNfNN'), 450),\n",
       " (('NNfNN', 'INfIN', 'DTfDT'), 366),\n",
       " (('REfRE', 'REfRE', 'REfRE'), 365),\n",
       " (('PPfPP', 'MDfMD', 'VVfVV'), 270),\n",
       " (('INfIN', 'DTfDT', 'JJfJJ'), 230),\n",
       " (('NNfNN', 'INfIN', 'NNfNN'), 204),\n",
       " (('JJfJJ', 'NNfNN', 'INfIN'), 202),\n",
       " (('PPfPP', 'VVPfVVP', 'PPfPP'), 195),\n",
       " (('PPfPP', 'VVPfVVP', 'RBfRB'), 188),\n",
       " (('DTfDT', 'NNfNN', 'NNfNN'), 186),\n",
       " (('PPfPP', 'VBSfVBS', 'RBfRB'), 186),\n",
       " (('INfIN', 'DTfDT', 'NNSfNNS'), 176),\n",
       " (('RBfRB', 'INfIN', 'DTfDT'), 158),\n",
       " (('PPfPP', 'VBPfVBP', 'VVGfVVG'), 157),\n",
       " (('DTfDT', 'NNfNN', 'CCfCC'), 154),\n",
       " (('TOfTO', 'VVfVV', 'INfIN'), 151),\n",
       " (('INfIN', 'PPfPP', 'VVPfVVP'), 148),\n",
       " (('DTfDT', 'NNfNN', 'PPfPP'), 144)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('INfIN', 'DTfDT', 'NNfNN')\n",
      "\tEnglish: 0.014982287976661804\n",
      "\tKorean: 0.010785081641260469\n",
      "\tFinnish: 0.015523567598080722\n",
      "\tTurkish: 0.019967241244832696\n",
      "\tDanish: 0.015679111009628193\n",
      "\tPortuguese: 0.01752612066059993\n",
      "\tPolish: 0.01934010278308796\n",
      "('DTfDT', 'NNfNN', 'INfIN')\n",
      "\tEnglish: 0.012085851219003959\n",
      "\tKorean: 0.008134000120503705\n",
      "\tFinnish: 0.012489415749364945\n",
      "\tTurkish: 0.01536541611418766\n",
      "\tDanish: 0.013871446512158922\n",
      "\tPortuguese: 0.014897202561509943\n",
      "\tPolish: 0.011594130936716403\n",
      "('DTfDT', 'JJfJJ', 'NNfNN')\n",
      "\tEnglish: 0.00937695353198583\n",
      "\tKorean: 0.008977526058926311\n",
      "\tFinnish: 0.011184024837708157\n",
      "\tTurkish: 0.013571484283597224\n",
      "\tDanish: 0.012273090535449253\n",
      "\tPortuguese: 0.0100438153016515\n",
      "\tPolish: 0.009185928151145759\n",
      "('NNfNN', 'INfIN', 'DTfDT')\n",
      "\tEnglish: 0.007626588872681809\n",
      "\tKorean: 0.006627703801891908\n",
      "\tFinnish: 0.010160880609652836\n",
      "\tTurkish: 0.011699555416894158\n",
      "\tDanish: 0.009209574913422384\n",
      "\tPortuguese: 0.010178631614425346\n",
      "\tPolish: 0.010352789294669679\n",
      "('REfRE', 'REfRE', 'REfRE')\n",
      "\tEnglish: 0.007605751198166285\n",
      "\tKorean: 0.020485629933120444\n",
      "\tFinnish: 0.01203076488851256\n",
      "\tTurkish: 0.001949925902815693\n",
      "\tDanish: 0.011645164973170453\n",
      "\tPortuguese: 0.003302999662959218\n",
      "\tPolish: 0.012612031083194716\n",
      "('PPfPP', 'MDfMD', 'VVfVV')\n",
      "\tEnglish: 0.005626172119191498\n",
      "\tKorean: 0.005603422305235886\n",
      "\tFinnish: 0.004904036127575501\n",
      "\tTurkish: 0.005303798455658685\n",
      "\tDanish: 0.004776039882787228\n",
      "\tPortuguese: 0.007954162453656892\n",
      "\tPolish: 0.0076963181806896895\n",
      "('INfIN', 'DTfDT', 'JJfJJ')\n",
      "\tEnglish: 0.004792665138570536\n",
      "\tKorean: 0.002892088931734651\n",
      "\tFinnish: 0.006879762912785775\n",
      "\tTurkish: 0.009047656189064815\n",
      "\tDanish: 0.00671690071164897\n",
      "\tPortuguese: 0.0064037748567576675\n",
      "\tPolish: 0.006405322872961096\n",
      "('NNfNN', 'INfIN', 'NNfNN')\n",
      "\tEnglish: 0.00425088560116691\n",
      "\tKorean: 0.0037356148701572574\n",
      "\tFinnish: 0.0033163985323172453\n",
      "\tTurkish: 0.004523828094532408\n",
      "\tDanish: 0.003558244852913194\n",
      "\tPortuguese: 0.0047185709470845974\n",
      "\tPolish: 0.003972293254549517\n",
      "('JJfJJ', 'NNfNN', 'INfIN')\n",
      "\tEnglish: 0.004209210252135861\n",
      "\tKorean: 0.004518888955835392\n",
      "\tFinnish: 0.004833474456675134\n",
      "\tTurkish: 0.007487715466812261\n",
      "\tDanish: 0.006374395859496899\n",
      "\tPortuguese: 0.0053252443545669026\n",
      "\tPolish: 0.004021946920231386\n",
      "('PPfPP', 'VVPfVVP', 'PPfPP')\n",
      "\tEnglish: 0.004063346530527193\n",
      "\tKorean: 0.0026510815207567632\n",
      "\tFinnish: 0.003810330228619814\n",
      "\tTurkish: 0.002495905155604087\n",
      "\tDanish: 0.004224226509875557\n",
      "\tPortuguese: 0.004448938321536906\n",
      "\tPolish: 0.002060627125797562\n"
     ]
    }
   ],
   "source": [
    "for trigram in eng_freq.most_common(10):\n",
    "    trigram = trigram[0]\n",
    "    print(trigram)\n",
    "    \n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common part-of-speech trigrams for Korean speakers. Compare with these frequencies with other L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('REfRE', 'REfRE', 'REfRE')\n",
      "\tKorean: 0.020485629933120444\n",
      "\tEnglish: 0.007605751198166285\n",
      "\tFinnish: 0.01203076488851256\n",
      "\tTurkish: 0.001949925902815693\n",
      "\tDanish: 0.011645164973170453\n",
      "\tPortuguese: 0.003302999662959218\n",
      "\tPolish: 0.012612031083194716\n",
      "('INfIN', 'DTfDT', 'NNfNN')\n",
      "\tKorean: 0.010785081641260469\n",
      "\tEnglish: 0.014982287976661804\n",
      "\tFinnish: 0.015523567598080722\n",
      "\tTurkish: 0.019967241244832696\n",
      "\tDanish: 0.015679111009628193\n",
      "\tPortuguese: 0.01752612066059993\n",
      "\tPolish: 0.01934010278308796\n",
      "('DTfDT', 'JJfJJ', 'NNfNN')\n",
      "\tKorean: 0.008977526058926311\n",
      "\tEnglish: 0.00937695353198583\n",
      "\tFinnish: 0.011184024837708157\n",
      "\tTurkish: 0.013571484283597224\n",
      "\tDanish: 0.012273090535449253\n",
      "\tPortuguese: 0.0100438153016515\n",
      "\tPolish: 0.009185928151145759\n",
      "('DTfDT', 'NNfNN', 'INfIN')\n",
      "\tKorean: 0.008134000120503705\n",
      "\tEnglish: 0.012085851219003959\n",
      "\tFinnish: 0.012489415749364945\n",
      "\tTurkish: 0.01536541611418766\n",
      "\tDanish: 0.013871446512158922\n",
      "\tPortuguese: 0.014897202561509943\n",
      "\tPolish: 0.011594130936716403\n",
      "('NNfNN', 'INfIN', 'DTfDT')\n",
      "\tKorean: 0.006627703801891908\n",
      "\tEnglish: 0.007626588872681809\n",
      "\tFinnish: 0.010160880609652836\n",
      "\tTurkish: 0.011699555416894158\n",
      "\tDanish: 0.009209574913422384\n",
      "\tPortuguese: 0.010178631614425346\n",
      "\tPolish: 0.010352789294669679\n",
      "('FWfFW', 'FWfFW', 'FWfFW')\n",
      "\tKorean: 0.006266192685425077\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 3.528083545018346e-05\n",
      "\tTurkish: 0.0\n",
      "\tDanish: 0.0008182060356966168\n",
      "\tPortuguese: 6.740815638692282e-05\n",
      "\tPolish: 0.002333722287047841\n",
      "('PPfPP', 'MDfMD', 'VVfVV')\n",
      "\tKorean: 0.005603422305235886\n",
      "\tEnglish: 0.005626172119191498\n",
      "\tFinnish: 0.004904036127575501\n",
      "\tTurkish: 0.005303798455658685\n",
      "\tDanish: 0.004776039882787228\n",
      "\tPortuguese: 0.007954162453656892\n",
      "\tPolish: 0.0076963181806896895\n",
      "('DTfDT', 'NNfNN', 'NNfNN')\n",
      "\tKorean: 0.005362414894257999\n",
      "\tEnglish: 0.0038758074598874764\n",
      "\tFinnish: 0.004022015241320914\n",
      "\tTurkish: 0.004133842913969269\n",
      "\tDanish: 0.0047570118354454466\n",
      "\tPortuguese: 0.0035726322885069094\n",
      "\tPolish: 0.004866059236823158\n",
      "('CDfCD', 'CDfCD', 'CDfCD')\n",
      "\tKorean: 0.00475989636681328\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 0.00010584250635055038\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.000266392662784945\n",
      "\tPortuguese: 0.0008088978766430738\n",
      "\tPolish: 0.0010179001464783138\n",
      "('NNfNN', 'NNfNN', 'INfIN')\n",
      "\tKorean: 0.004639392661324336\n",
      "\tEnglish: 0.0017086893102729735\n",
      "\tFinnish: 0.0013406717471069714\n",
      "\tTurkish: 0.0026518992278293423\n",
      "\tDanish: 0.0024355900597480685\n",
      "\tPortuguese: 0.0020222446916076846\n",
      "\tPolish: 0.0028799126095483997\n"
     ]
    }
   ],
   "source": [
    "for trigram in kor_freq.most_common(10):\n",
    "    trigram = trigram[0]\n",
    "    print(trigram)\n",
    "    \n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common part-of-speech trigrams for Finnish speakers. Compare with these frequencies with other L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('INfIN', 'DTfDT', 'NNfNN')\n",
      "\tFinnish: 0.015523567598080722\n",
      "\tEnglish: 0.014982287976661804\n",
      "\tKorean: 0.010785081641260469\n",
      "\tTurkish: 0.019967241244832696\n",
      "\tDanish: 0.015679111009628193\n",
      "\tPortuguese: 0.01752612066059993\n",
      "\tPolish: 0.01934010278308796\n",
      "('DTfDT', 'NNfNN', 'INfIN')\n",
      "\tFinnish: 0.012489415749364945\n",
      "\tEnglish: 0.012085851219003959\n",
      "\tKorean: 0.008134000120503705\n",
      "\tTurkish: 0.01536541611418766\n",
      "\tDanish: 0.013871446512158922\n",
      "\tPortuguese: 0.014897202561509943\n",
      "\tPolish: 0.011594130936716403\n",
      "('REfRE', 'REfRE', 'REfRE')\n",
      "\tFinnish: 0.01203076488851256\n",
      "\tEnglish: 0.007605751198166285\n",
      "\tKorean: 0.020485629933120444\n",
      "\tTurkish: 0.001949925902815693\n",
      "\tDanish: 0.011645164973170453\n",
      "\tPortuguese: 0.003302999662959218\n",
      "\tPolish: 0.012612031083194716\n",
      "('DTfDT', 'JJfJJ', 'NNfNN')\n",
      "\tFinnish: 0.011184024837708157\n",
      "\tEnglish: 0.00937695353198583\n",
      "\tKorean: 0.008977526058926311\n",
      "\tTurkish: 0.013571484283597224\n",
      "\tDanish: 0.012273090535449253\n",
      "\tPortuguese: 0.0100438153016515\n",
      "\tPolish: 0.009185928151145759\n",
      "('NNfNN', 'INfIN', 'DTfDT')\n",
      "\tFinnish: 0.010160880609652836\n",
      "\tEnglish: 0.007626588872681809\n",
      "\tKorean: 0.006627703801891908\n",
      "\tTurkish: 0.011699555416894158\n",
      "\tDanish: 0.009209574913422384\n",
      "\tPortuguese: 0.010178631614425346\n",
      "\tPolish: 0.010352789294669679\n",
      "('INfIN', 'DTfDT', 'JJfJJ')\n",
      "\tFinnish: 0.006879762912785775\n",
      "\tEnglish: 0.004792665138570536\n",
      "\tKorean: 0.002892088931734651\n",
      "\tTurkish: 0.009047656189064815\n",
      "\tDanish: 0.00671690071164897\n",
      "\tPortuguese: 0.0064037748567576675\n",
      "\tPolish: 0.006405322872961096\n",
      "('PPfPP', 'MDfMD', 'VVfVV')\n",
      "\tFinnish: 0.004904036127575501\n",
      "\tEnglish: 0.005626172119191498\n",
      "\tKorean: 0.005603422305235886\n",
      "\tTurkish: 0.005303798455658685\n",
      "\tDanish: 0.004776039882787228\n",
      "\tPortuguese: 0.007954162453656892\n",
      "\tPolish: 0.0076963181806896895\n",
      "('JJfJJ', 'NNfNN', 'INfIN')\n",
      "\tFinnish: 0.004833474456675134\n",
      "\tEnglish: 0.004209210252135861\n",
      "\tKorean: 0.004518888955835392\n",
      "\tTurkish: 0.007487715466812261\n",
      "\tDanish: 0.006374395859496899\n",
      "\tPortuguese: 0.0053252443545669026\n",
      "\tPolish: 0.004021946920231386\n",
      "('PPfPP', 'VVPfVVP', 'RBfRB')\n",
      "\tFinnish: 0.004727631950324583\n",
      "\tEnglish: 0.003917482808918525\n",
      "\tKorean: 0.003554859311923842\n",
      "\tTurkish: 0.0031978784806177365\n",
      "\tDanish: 0.003482132663546067\n",
      "\tPortuguese: 0.005729693292888439\n",
      "\tPolish: 0.004270215248640731\n",
      "('INfIN', 'DTfDT', 'NNSfNNS')\n",
      "\tFinnish: 0.0042689810894721986\n",
      "\tEnglish: 0.003667430714732236\n",
      "\tKorean: 0.0011447852021449659\n",
      "\tTurkish: 0.003665860697293503\n",
      "\tDanish: 0.0034440765688625035\n",
      "\tPortuguese: 0.005729693292888439\n",
      "\tPolish: 0.004046773753072321\n"
     ]
    }
   ],
   "source": [
    "for trigram in fin_freq.most_common(10):\n",
    "    trigram = trigram[0]\n",
    "    print(trigram)\n",
    "    \n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get native speaker trigram outliers (in terms of frequency vs. other L1s)\n",
    "Some tags to get rid of: BR(breathing), PA(pause), UH(interjections and hesitations), UNI(unintelligible), UNK(unknown)\n",
    "https://www.univie.ac.at/voice/page/documents/VOICE_tagging_manual.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_common = {}\n",
    "less_common = {}\n",
    "\n",
    "for trigram in eng_freq:\n",
    "    #trigram = trigram[0]\n",
    "    \n",
    "    avg = 0\n",
    "    avg = avg + (kor_freq[trigram] / len(kor_tag_trigrams))\n",
    "    avg = avg + (fin_freq[trigram] / len(fin_tag_trigrams))\n",
    "    avg = avg + (tur_freq[trigram] / len(tur_tag_trigrams))\n",
    "    avg = avg + (dan_freq[trigram] / len(dan_tag_trigrams))\n",
    "    avg = avg + (por_freq[trigram] / len(por_tag_trigrams))\n",
    "    avg = avg + (pol_freq[trigram] / len(pol_tag_trigrams))\n",
    "    \n",
    "    avg /= 6\n",
    "    \n",
    "    eng_percent = (eng_freq[trigram] / len(eng_tag_trigrams))\n",
    "    if eng_percent > (avg * 2) and eng_freq[trigram] > 5:\n",
    "        more_common[trigram] = eng_freq[trigram]\n",
    "        \n",
    "        \n",
    "    if eng_percent < (avg * 0.5) and eng_freq[trigram] > 5:\n",
    "        less_common[trigram] = eng_freq[trigram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native trigram outliers -- more frequent that other L1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PPfPP', 'VHPfVHP', 'VVNfVVN')\n",
      "\tEnglish: 0.002208793498645551\n",
      "\tFinnish: 0.00091730172170477\n",
      "\tKorean: 0.0006627703801891908\n",
      "\tTurkish: 0.0006239762889010217\n",
      "\tDanish: 0.0012748791718993797\n",
      "\tPortuguese: 0.0006066734074823053\n",
      "\tPolish: 0.001390302639092331\n",
      "('PPfPP', 'VBDfVBD', 'VVGfVVG')\n",
      "\tEnglish: 0.0013752865180245884\n",
      "\tFinnish: 0.0003175275190516511\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0004186170415191993\n",
      "\tPortuguese: 0.0013481631277384564\n",
      "\tPolish: 0.0004965366568186896\n",
      "('VBPfVBP', 'VVGfVVG', 'INfIN')\n",
      "\tEnglish: 0.0013336111689935403\n",
      "\tFinnish: 0.0009525825571549535\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.0007019733250136495\n",
      "\tDanish: 0.0006088975149370171\n",
      "\tPortuguese: 0.0009437141894169194\n",
      "\tPolish: 0.0007199781523870999\n",
      "('DTfDT', 'VBSfVBS', 'RBfRB')\n",
      "\tEnglish: 0.0010418837257762034\n",
      "\tFinnish: 0.0007056167090036692\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 7.799703611262772e-05\n",
      "\tDanish: 0.000799177988354835\n",
      "\tPortuguese: 0.0\n",
      "\tPolish: 0.0003972293254549517\n",
      "('PREfPRE', 'PPfPP', 'VVPfVVP')\n",
      "\tEnglish: 0.0007709939570743905\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.0\n",
      "\tTurkish: 0.00023399110833788317\n",
      "\tDanish: 0.00032347680481029036\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.0002730951612502793\n",
      "('VBSfVBS', 'RBfRB', 'DTfDT')\n",
      "\tEnglish: 0.0007501562825588665\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0005137572782281082\n",
      "\tPortuguese: 0.00020222446916076846\n",
      "\tPolish: 0.00019861466272747585\n",
      "('VBDfVBD', 'VVGfVVG', 'INfIN')\n",
      "\tEnglish: 0.0006459679099812461\n",
      "\tFinnish: 0.00010584250635055038\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.00011416828405069072\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.00017378782988654139\n",
      "('INfIN', 'WPfWP', 'PPfPP')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.0001764041772509173\n",
      "\tKorean: 0.00012050370548894379\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0006659816569623625\n",
      "\tPortuguese: 0.0004718570947084597\n",
      "\tPolish: 0.00019861466272747585\n",
      "('INfIN', 'PPfPP', 'REfRE')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.00021168501270110075\n",
      "\tKorean: 0.00036151111646683137\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.00030444875746850857\n",
      "\tPortuguese: 0.0002696326255476913\n",
      "\tPolish: 0.00022344149556841034\n",
      "('NNSfNNS', 'PREfPRE', 'VVPfVVP')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.0002469658481512842\n",
      "\tKorean: 0.00018075555823341568\n",
      "\tTurkish: 7.799703611262772e-05\n",
      "\tDanish: 0.00020930852075959965\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.0002482683284093448\n"
     ]
    }
   ],
   "source": [
    "for trigram in sorted(more_common, key=more_common.get, reverse=True)[:10]:\n",
    "    print(trigram)\n",
    "    \n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native trigram outliers -- less frequent that other L1s. (Maybe try this again, but excluding pause and hesitation tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PPfPP', 'VHPfVHP', 'DTfDT')\n",
      "\tEnglish: 0.0006876432590122942\n",
      "\tFinnish: 0.0010231442280553204\n",
      "\tKorean: 0.0014460444658673255\n",
      "\tTurkish: 0.001403946650027299\n",
      "\tDanish: 0.0018266925448110515\n",
      "\tPortuguese: 0.0019548365352207615\n",
      "\tPolish: 0.0008192854837508379\n",
      "('PPfPP', 'PPfPP', 'PPfPP')\n",
      "\tEnglish: 0.0004584288393415295\n",
      "\tFinnish: 0.000458650860852385\n",
      "\tKorean: 0.0007230222329336627\n",
      "\tTurkish: 0.00023399110833788317\n",
      "\tDanish: 0.001788636450127488\n",
      "\tPortuguese: 0.0018874283788338389\n",
      "\tPolish: 0.0005710171553414931\n",
      "('NPfNP', 'CCfCC', 'NPfNP')\n",
      "\tEnglish: 0.0004375911648260054\n",
      "\tFinnish: 0.0005644933672029354\n",
      "\tKorean: 0.0025908296680122915\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.0005137572782281082\n",
      "\tPortuguese: 0.0010785305021907652\n",
      "\tPolish: 0.0005958439881824276\n",
      "('CCfCC', 'DTfDT', 'JJfJJ')\n",
      "\tEnglish: 0.0003959158157949573\n",
      "\tFinnish: 0.0011289867344058708\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 0.001949925902815693\n",
      "\tDanish: 0.0007611218936712714\n",
      "\tPortuguese: 0.0009437141894169194\n",
      "\tPolish: 0.0004468829911368207\n",
      "('DTfDT', 'NPfNP', 'NNfNN')\n",
      "\tEnglish: 0.00037507814127943324\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.0008435259384226065\n",
      "\tTurkish: 0.000545979252788394\n",
      "\tDanish: 0.001617384024051452\n",
      "\tPortuguese: 0.0004718570947084597\n",
      "\tPolish: 0.0007448049852280344\n",
      "('RBfRB', 'PPfPP', 'VHPfVHP')\n",
      "\tEnglish: 0.00037507814127943324\n",
      "\tFinnish: 0.0005644933672029354\n",
      "\tKorean: 0.0007832740856781347\n",
      "\tTurkish: 0.0010139614694641603\n",
      "\tDanish: 0.0008182060356966168\n",
      "\tPortuguese: 0.0005392652510953826\n",
      "\tPolish: 0.0008192854837508379\n",
      "('NPfNP', 'CCfCC', 'PPfPP')\n",
      "\tEnglish: 0.0003542404667639091\n",
      "\tFinnish: 0.0003880891899520181\n",
      "\tKorean: 0.0009037777911670784\n",
      "\tTurkish: 0.0006239762889010217\n",
      "\tDanish: 0.000799177988354835\n",
      "\tPortuguese: 0.0008088978766430738\n",
      "\tPolish: 0.0007696318180689689\n",
      "('EXfEX', 'VBZfVBZ', 'DTfDT')\n",
      "\tEnglish: 0.0003542404667639091\n",
      "\tFinnish: 0.0005292125317527519\n",
      "\tKorean: 0.00048201482195577515\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.00053278532556989\n",
      "\tPortuguese: 0.0006740815638692282\n",
      "\tPolish: 0.0011420343106829862\n",
      "('CDfCD', 'CDfCD', 'CDfCD')\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 0.00010584250635055038\n",
      "\tKorean: 0.00475989636681328\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.000266392662784945\n",
      "\tPortuguese: 0.0008088978766430738\n",
      "\tPolish: 0.0010179001464783138\n",
      "('FWfFW', 'FWfFW', 'FWfFW')\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 3.528083545018346e-05\n",
      "\tKorean: 0.006266192685425077\n",
      "\tTurkish: 0.0\n",
      "\tDanish: 0.0008182060356966168\n",
      "\tPortuguese: 6.740815638692282e-05\n",
      "\tPolish: 0.002333722287047841\n"
     ]
    }
   ],
   "source": [
    "for trigram in sorted(less_common, key=less_common.get, reverse=True)[:10]:\n",
    "    print(trigram)\n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing discourse markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discourse_markers(speech):\n",
    "    dm_list = []\n",
    "    markers = [[t for t in u if t[1] == \"DMfDM\"] for u in speech]\n",
    "    for m in markers:\n",
    "        dm_list.extend(m)\n",
    "        \n",
    "    #return dm_list\n",
    "    return dm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_dm = get_discourse_markers(eng_speech)\n",
    "kor_dm = get_discourse_markers(kor_speech)\n",
    "fin_dm = get_discourse_markers(fin_speech)\n",
    "tur_dm = get_discourse_markers(tur_speech)\n",
    "dan_dm = get_discourse_markers(dan_speech)\n",
    "por_dm = get_discourse_markers(por_speech)\n",
    "pol_dm = get_discourse_markers(pol_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dm_percent(speech, dm_list):\n",
    "    total = 0\n",
    "    for u in speech:\n",
    "        total += len(u)\n",
    "    \n",
    "    return len(dm_list)/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of discourse markers across L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.01287</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.017388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.014251   0.013229    0.012288    0.010293   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions    0.01287       0.008287   0.017388  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "dm_df['L1=English'] = get_dm_percent(eng_speech, eng_dm)\n",
    "dm_df['L1=Korean'] = get_dm_percent(kor_speech, kor_dm)\n",
    "dm_df['L1=Finnish'] = get_dm_percent(fin_speech, fin_dm)\n",
    "dm_df['L1=Turkish'] = get_dm_percent(tur_speech, tur_dm)\n",
    "dm_df['L1=Danish'] = get_dm_percent(dan_speech, dan_dm)\n",
    "dm_df['L1=Portuguese'] = get_dm_percent(por_speech, por_dm)\n",
    "dm_df['L1=Polish'] = get_dm_percent(pol_speech, pol_dm)\n",
    "\n",
    "dm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_dm_words = [dm[0].replace('\\n', '') for dm in eng_dm]\n",
    "kor_dm_words = [dm[0].replace('\\n', '') for dm in kor_dm]\n",
    "fin_dm_words = [dm[0].replace('\\n', '') for dm in fin_dm]\n",
    "tur_dm_words = [dm[0].replace('\\n', '') for dm in tur_dm]\n",
    "dan_dm_words = [dm[0].replace('\\n', '') for dm in dan_dm]\n",
    "por_dm_words = [dm[0].replace('\\n', '') for dm in por_dm]\n",
    "pol_dm_words = [dm[0].replace('\\n', '') for dm in pol_dm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 202,\n",
       "          'look': 1,\n",
       "          'right': 50,\n",
       "          'so': 419,\n",
       "          'well': 116,\n",
       "          'whatever': 13})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dm_freqs = nltk.FreqDist(eng_dm_words)\n",
    "eng_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 55, 'right': 33, 'so': 174, 'well': 27, 'whatever': 4})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_dm_freqs = nltk.FreqDist(kor_dm_words)\n",
    "kor_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 111, 'right': 10, 'so': 226, 'well': 72, 'whatever': 8})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_dm_freqs = nltk.FreqDist(fin_dm_words)\n",
    "fin_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 16, 'right': 15, 'so': 119, 'well': 13, 'whatever': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_dm_freqs = nltk.FreqDist(tur_dm_words)\n",
    "tur_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 125, 'right': 30, 'so': 499, 'well': 137, 'whatever': 16})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dan_dm_freqs = nltk.FreqDist(dan_dm_words)\n",
    "dan_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.01287</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.017388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.014251   0.013229    0.012288    0.010293   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions    0.01287       0.008287   0.017388  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_dm_freqs = nltk.FreqDist(por_dm_words)\n",
    "dm_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "dm_df['L1=English'] = get_dm_percent(eng_speech, eng_dm)\n",
    "dm_df['L1=Korean'] = get_dm_percent(kor_speech, kor_dm)\n",
    "dm_df['L1=Finnish'] = get_dm_percent(fin_speech, fin_dm)\n",
    "dm_df['L1=Turkish'] = get_dm_percent(tur_speech, tur_dm)\n",
    "dm_df['L1=Danish'] = get_dm_percent(dan_speech, dan_dm)\n",
    "dm_df['L1=Portuguese'] = get_dm_percent(por_speech, por_dm)\n",
    "dm_df['L1=Polish'] = get_dm_percent(pol_speech, pol_dm)\n",
    "\n",
    "dm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 265,\n",
       "          'look': 1,\n",
       "          'right': 40,\n",
       "          'so': 450,\n",
       "          'well': 66,\n",
       "          'whatever': 28})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_dm_freqs = nltk.FreqDist(pol_dm_words)\n",
    "pol_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>so</th>\n",
       "      <td>0.523096</td>\n",
       "      <td>0.593857</td>\n",
       "      <td>0.529274</td>\n",
       "      <td>0.72561</td>\n",
       "      <td>0.61834</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.252185</td>\n",
       "      <td>0.187713</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.154895</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.311765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>0.144819</td>\n",
       "      <td>0.0921502</td>\n",
       "      <td>0.168618</td>\n",
       "      <td>0.0792683</td>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.0980392</td>\n",
       "      <td>0.0776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.062422</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>0.0234192</td>\n",
       "      <td>0.0914634</td>\n",
       "      <td>0.0371747</td>\n",
       "      <td>0.0196078</td>\n",
       "      <td>0.0470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatever</th>\n",
       "      <td>0.0162297</td>\n",
       "      <td>0.0136519</td>\n",
       "      <td>0.0187354</td>\n",
       "      <td>0.00609756</td>\n",
       "      <td>0.0198265</td>\n",
       "      <td>0.0196078</td>\n",
       "      <td>0.0329412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>0.00124844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00117647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L1=English  L1=Korean L1=Finnish  L1=Turkish  L1=Danish  \\\n",
       "so          0.523096   0.593857   0.529274     0.72561    0.61834   \n",
       "like        0.252185   0.187713   0.259953    0.097561   0.154895   \n",
       "well        0.144819  0.0921502   0.168618   0.0792683   0.169765   \n",
       "right       0.062422   0.112628  0.0234192   0.0914634  0.0371747   \n",
       "whatever   0.0162297  0.0136519  0.0187354  0.00609756  0.0198265   \n",
       "look      0.00124844          0          0           0          0   \n",
       "\n",
       "         L1=Portuguese   L1=Polish  \n",
       "so            0.745098    0.529412  \n",
       "like          0.117647    0.311765  \n",
       "well         0.0980392   0.0776471  \n",
       "right        0.0196078   0.0470588  \n",
       "whatever     0.0196078   0.0329412  \n",
       "look                 0  0.00117647  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourse_markers = eng_dm_freqs.most_common()\n",
    "discourse_markers = [b[0] for b in discourse_markers]\n",
    "\n",
    "dm_words_df = pd.DataFrame(index = discourse_markers, columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "for word in discourse_markers:\n",
    "    dm_words_df['L1=English'][word] = eng_dm_freqs[word]/sum(eng_dm_freqs.values())\n",
    "    dm_words_df['L1=Korean'][word] = kor_dm_freqs[word]/sum(kor_dm_freqs.values())\n",
    "    dm_words_df['L1=Finnish'][word] = fin_dm_freqs[word]/sum(fin_dm_freqs.values())\n",
    "    dm_words_df['L1=Turkish'][word] = tur_dm_freqs[word]/sum(tur_dm_freqs.values())\n",
    "    dm_words_df['L1=Danish'][word] = dan_dm_freqs[word]/sum(dan_dm_freqs.values())\n",
    "    dm_words_df['L1=Portuguese'][word] = por_dm_freqs[word]/sum(por_dm_freqs.values())\n",
    "    dm_words_df['L1=Polish'][word] = pol_dm_freqs[word]/sum(pol_dm_freqs.values())\n",
    "    \n",
    "dm_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting distribution of specific discourse markers across specific L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_count(speech):\n",
    "    total = 0\n",
    "    for u in speech:\n",
    "        total += len(u)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so\n",
      "\tEnglish: 0.5230961298377028\n",
      "\tFinnish: 0.5292740046838408\n",
      "\tKorean: 0.5938566552901023\n",
      "\tTurkish: 0.725609756097561\n",
      "\tDanish: 0.6183395291201983\n",
      "\tPortuguese: 0.7450980392156863\n",
      "\tPolish: 0.5294117647058824\n",
      "well\n",
      "\tEnglish: 0.14481897627965043\n",
      "\tFinnish: 0.1686182669789227\n",
      "\tKorean: 0.09215017064846416\n",
      "\tTurkish: 0.07926829268292683\n",
      "\tDanish: 0.1697645600991326\n",
      "\tPortuguese: 0.09803921568627451\n",
      "\tPolish: 0.07764705882352942\n",
      "like\n",
      "\tEnglish: 0.25218476903870163\n",
      "\tFinnish: 0.25995316159250587\n",
      "\tKorean: 0.18771331058020477\n",
      "\tTurkish: 0.0975609756097561\n",
      "\tDanish: 0.15489467162329615\n",
      "\tPortuguese: 0.11764705882352941\n",
      "\tPolish: 0.31176470588235294\n",
      "right\n",
      "\tEnglish: 0.062421972534332085\n",
      "\tFinnish: 0.0234192037470726\n",
      "\tKorean: 0.11262798634812286\n",
      "\tTurkish: 0.09146341463414634\n",
      "\tDanish: 0.03717472118959108\n",
      "\tPortuguese: 0.0196078431372549\n",
      "\tPolish: 0.047058823529411764\n",
      "whatever\n",
      "\tEnglish: 0.016229712858926344\n",
      "\tFinnish: 0.01873536299765808\n",
      "\tKorean: 0.013651877133105802\n",
      "\tTurkish: 0.006097560975609756\n",
      "\tDanish: 0.01982651796778191\n",
      "\tPortuguese: 0.0196078431372549\n",
      "\tPolish: 0.03294117647058824\n",
      "look\n",
      "\tEnglish: 0.0012484394506866417\n",
      "\tFinnish: 0.0\n",
      "\tKorean: 0.0\n",
      "\tTurkish: 0.0\n",
      "\tDanish: 0.0\n",
      "\tPortuguese: 0.0\n",
      "\tPolish: 0.001176470588235294\n"
     ]
    }
   ],
   "source": [
    "for dm in eng_dm_freqs:\n",
    "    print(dm)\n",
    "    print(\"\\tEnglish: \" + str(eng_dm_freqs[dm] / len(eng_dm_words)))\n",
    "    print(\"\\tFinnish: \" + str(fin_dm_freqs[dm] / len(fin_dm_words)))\n",
    "    print(\"\\tKorean: \" + str(kor_dm_freqs[dm] / len(kor_dm_words)))\n",
    "    print(\"\\tTurkish: \" + str(tur_dm_freqs[dm] / len(tur_dm_words)))\n",
    "    print(\"\\tDanish: \" + str(dan_dm_freqs[dm] / len(dan_dm_words)))\n",
    "    print(\"\\tPortuguese: \" + str(por_dm_freqs[dm] / len(por_dm_words)))\n",
    "    print(\"\\tPolish: \" + str(pol_dm_freqs[dm] / len(pol_dm_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Article/Determiner Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eng_speech -- (word, tag) tupes\n",
    "#eng_tags -- list of tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_words(li):\n",
    "    count = 0\n",
    "    for u in li:\n",
    "        count += len(u)\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determiner_words(li):\n",
    "    words = []\n",
    "    \n",
    "    for utterance in li:\n",
    "        for pair in utterance:\n",
    "            if pair[1] == \"DTfDT\":\n",
    "                words.append(pair[0].replace(\"\\n\", \"\"))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.092807</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.106683</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>0.094908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.092807   0.085427    0.107176    0.106683   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions   0.106743       0.107973   0.094908  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "eng_dets = determiner_words(eng_speech)\n",
    "kor_dets = determiner_words(kor_speech)\n",
    "fin_dets = determiner_words(fin_speech)\n",
    "tur_dets = determiner_words(tur_speech)\n",
    "dan_dets = determiner_words(dan_speech)\n",
    "por_dets = determiner_words(por_speech)\n",
    "pol_dets = determiner_words(pol_speech)\n",
    "\n",
    "det_df['L1=English'] = len(eng_dets)/len(eng_toks)\n",
    "det_df['L1=Korean'] = len(kor_dets)/len(kor_toks)\n",
    "det_df['L1=Finnish'] = len(fin_dets)/len(fin_toks)\n",
    "det_df['L1=Turkish'] = len(tur_dets)/len(tur_toks)\n",
    "det_df['L1=Danish'] = len(dan_dets)/len(dan_toks)\n",
    "det_df['L1=Portuguese'] = len(por_dets)/len(por_toks)\n",
    "det_df['L1=Polish'] = len(pol_dets)/len(pol_toks)\n",
    "\n",
    "det_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing specfic determiner words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_det_words = nltk.FreqDist(eng_dets)\n",
    "kor_det_words = nltk.FreqDist(kor_dets)\n",
    "fin_det_words = nltk.FreqDist(fin_dets)\n",
    "tur_det_words = nltk.FreqDist(tur_dets)\n",
    "dan_det_words = nltk.FreqDist(dan_dets)\n",
    "por_det_words = nltk.FreqDist(por_dets)\n",
    "pol_det_words = nltk.FreqDist(pol_dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0406318</td>\n",
       "      <td>0.0398819</td>\n",
       "      <td>0.0539406</td>\n",
       "      <td>0.0626998</td>\n",
       "      <td>0.0489002</td>\n",
       "      <td>0.0549302</td>\n",
       "      <td>0.0509173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.0178155</td>\n",
       "      <td>0.0127719</td>\n",
       "      <td>0.0151697</td>\n",
       "      <td>0.0140373</td>\n",
       "      <td>0.0213677</td>\n",
       "      <td>0.0163106</td>\n",
       "      <td>0.011668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.0147108</td>\n",
       "      <td>0.0094584</td>\n",
       "      <td>0.0138997</td>\n",
       "      <td>0.0113858</td>\n",
       "      <td>0.0148984</td>\n",
       "      <td>0.00660511</td>\n",
       "      <td>0.00638018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.00683447</td>\n",
       "      <td>0.00885596</td>\n",
       "      <td>0.0102307</td>\n",
       "      <td>0.00600484</td>\n",
       "      <td>0.00808661</td>\n",
       "      <td>0.0137494</td>\n",
       "      <td>0.0140513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>0.00254209</td>\n",
       "      <td>0.00668715</td>\n",
       "      <td>0.00225781</td>\n",
       "      <td>0.00327536</td>\n",
       "      <td>0.0026448</td>\n",
       "      <td>0.00431354</td>\n",
       "      <td>0.00245773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.00245874</td>\n",
       "      <td>0.000421712</td>\n",
       "      <td>0.00201087</td>\n",
       "      <td>0.00116977</td>\n",
       "      <td>0.00323464</td>\n",
       "      <td>0.00155018</td>\n",
       "      <td>0.00109233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.00195866</td>\n",
       "      <td>0.00174709</td>\n",
       "      <td>0.00201087</td>\n",
       "      <td>0.00194962</td>\n",
       "      <td>0.00213106</td>\n",
       "      <td>0.00269596</td>\n",
       "      <td>0.00181227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these</th>\n",
       "      <td>0.0018128</td>\n",
       "      <td>0.000903669</td>\n",
       "      <td>0.00268115</td>\n",
       "      <td>0.0015597</td>\n",
       "      <td>0.00121775</td>\n",
       "      <td>0.00141538</td>\n",
       "      <td>0.000744768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0.000958493</td>\n",
       "      <td>0.00126514</td>\n",
       "      <td>0.00105835</td>\n",
       "      <td>0.00124776</td>\n",
       "      <td>0.000932339</td>\n",
       "      <td>0.00155018</td>\n",
       "      <td>0.00131576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>those</th>\n",
       "      <td>0.000812635</td>\n",
       "      <td>0.000662691</td>\n",
       "      <td>0.00116419</td>\n",
       "      <td>0.00132574</td>\n",
       "      <td>0.00078012</td>\n",
       "      <td>0.00128058</td>\n",
       "      <td>0.00139023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.000770962</td>\n",
       "      <td>0.000481957</td>\n",
       "      <td>0.000458618</td>\n",
       "      <td>0.000389924</td>\n",
       "      <td>0.000799148</td>\n",
       "      <td>0.000943587</td>\n",
       "      <td>0.000546163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0.000666778</td>\n",
       "      <td>0.000903669</td>\n",
       "      <td>0.000917237</td>\n",
       "      <td>0.000623879</td>\n",
       "      <td>0.000951366</td>\n",
       "      <td>0.000943587</td>\n",
       "      <td>0.00084407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>0.000375063</td>\n",
       "      <td>0.000180734</td>\n",
       "      <td>0.000493897</td>\n",
       "      <td>0.000467909</td>\n",
       "      <td>0.000247355</td>\n",
       "      <td>0.000808789</td>\n",
       "      <td>0.00022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>0.000229205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000141113</td>\n",
       "      <td>0</td>\n",
       "      <td>9.51366e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000248256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>both</th>\n",
       "      <td>0.000166694</td>\n",
       "      <td>0.000180734</td>\n",
       "      <td>0.000458618</td>\n",
       "      <td>0.000233955</td>\n",
       "      <td>0.00028541</td>\n",
       "      <td>0.000471793</td>\n",
       "      <td>0.00022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every</th>\n",
       "      <td>6.25104e-05</td>\n",
       "      <td>0.00102416</td>\n",
       "      <td>0.000282227</td>\n",
       "      <td>0.000311939</td>\n",
       "      <td>0.000133191</td>\n",
       "      <td>0.000404394</td>\n",
       "      <td>0.000968198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L1=English    L1=Korean   L1=Finnish   L1=Turkish    L1=Danish  \\\n",
       "the        0.0406318    0.0398819    0.0539406    0.0626998    0.0489002   \n",
       "a          0.0178155    0.0127719    0.0151697    0.0140373    0.0213677   \n",
       "that       0.0147108    0.0094584    0.0138997    0.0113858    0.0148984   \n",
       "this      0.00683447   0.00885596    0.0102307   0.00600484   0.00808661   \n",
       "some      0.00254209   0.00668715   0.00225781   0.00327536    0.0026448   \n",
       "an        0.00245874  0.000421712   0.00201087   0.00116977   0.00323464   \n",
       "all       0.00195866   0.00174709   0.00201087   0.00194962   0.00213106   \n",
       "these      0.0018128  0.000903669   0.00268115    0.0015597   0.00121775   \n",
       "any      0.000958493   0.00126514   0.00105835   0.00124776  0.000932339   \n",
       "those    0.000812635  0.000662691   0.00116419   0.00132574   0.00078012   \n",
       "another  0.000770962  0.000481957  0.000458618  0.000389924  0.000799148   \n",
       "no       0.000666778  0.000903669  0.000917237  0.000623879  0.000951366   \n",
       "each     0.000375063  0.000180734  0.000493897  0.000467909  0.000247355   \n",
       "such     0.000229205            0  0.000141113            0  9.51366e-05   \n",
       "both     0.000166694  0.000180734  0.000458618  0.000233955   0.00028541   \n",
       "every    6.25104e-05   0.00102416  0.000282227  0.000311939  0.000133191   \n",
       "\n",
       "        L1=Portuguese    L1=Polish  \n",
       "the         0.0549302    0.0509173  \n",
       "a           0.0163106     0.011668  \n",
       "that       0.00660511   0.00638018  \n",
       "this        0.0137494    0.0140513  \n",
       "some       0.00431354   0.00245773  \n",
       "an         0.00155018   0.00109233  \n",
       "all        0.00269596   0.00181227  \n",
       "these      0.00141538  0.000744768  \n",
       "any        0.00155018   0.00131576  \n",
       "those      0.00128058   0.00139023  \n",
       "another   0.000943587  0.000546163  \n",
       "no        0.000943587   0.00084407  \n",
       "each      0.000808789   0.00022343  \n",
       "such                0  0.000248256  \n",
       "both      0.000471793   0.00022343  \n",
       "every     0.000404394  0.000968198  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "det_words = eng_det_words.most_common()\n",
    "det_words = [b[0] for b in det_words]\n",
    "\n",
    "det_words_df = pd.DataFrame(index = det_words, columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "for word in det_words:\n",
    "    det_words_df['L1=English'][word] = eng_det_words[word]/len(eng_toks)\n",
    "    det_words_df['L1=Korean'][word] = kor_det_words[word]/len(kor_toks)\n",
    "    det_words_df['L1=Finnish'][word] = fin_det_words[word]/len(fin_toks)\n",
    "    det_words_df['L1=Turkish'][word] = tur_det_words[word]/len(tur_toks)\n",
    "    det_words_df['L1=Danish'][word] = dan_det_words[word]/len(dan_toks)\n",
    "    det_words_df['L1=Portuguese'][word] = por_det_words[word]/len(por_toks)\n",
    "    det_words_df['L1=Polish'][word] = pol_det_words[word]/len(pol_toks)\n",
    "det_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
