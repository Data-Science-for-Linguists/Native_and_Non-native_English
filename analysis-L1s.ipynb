{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_tokenized.p', 'rb')\n",
    "VOICE_toks = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_tagged.p', 'rb')\n",
    "VOICE_tags = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_native_tagged.p', 'rb')\n",
    "VOICE_native_tags = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_participant_info.p', 'rb')\n",
    "participants = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_monolingual_speakers(participant_dict, language):\n",
    "    speakers = []\n",
    "    for p in participant_dict.keys():\n",
    "        L1s = participant_dict[p]['L1']\n",
    "        if(len(L1s) == 1 and language in L1s):\n",
    "            speakers.append(p)\n",
    "            \n",
    "    return speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_speakers = get_monolingual_speakers(participants, 'eng')\n",
    "pol_speakers = get_monolingual_speakers(participants, 'pol')\n",
    "kor_speakers = get_monolingual_speakers(participants, 'kor')\n",
    "fin_speakers = get_monolingual_speakers(participants, 'fin')\n",
    "dan_speakers = get_monolingual_speakers(participants, 'dan')\n",
    "tur_speakers = get_monolingual_speakers(participants, 'tur')\n",
    "hun_speakers = get_monolingual_speakers(participants, 'hun')\n",
    "por_speakers = get_monolingual_speakers(participants, 'por')\n",
    "rus_speakers = get_monolingual_speakers(participants, 'rus')\n",
    "mlt_speakers = get_monolingual_speakers(participants, 'mlt')\n",
    "lav_speakers = get_monolingual_speakers(participants, 'lav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English speakers: 62\n",
      "Polish speakers: 35\n",
      "Korean speakers: 14\n",
      "Finnish speakers: 51\n",
      "Danish speakers: 35\n",
      "Turkish speakers: 14\n",
      "Hungarian speakers: 13\n",
      "Portuguese speakers: 21\n",
      "Russian speakers: 22\n",
      "Maltese speakers: 22\n",
      "Latvian speakers: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"English speakers:\", len(eng_speakers))\n",
    "print(\"Polish speakers:\", len(pol_speakers))\n",
    "print(\"Korean speakers:\", len(kor_speakers))\n",
    "print(\"Finnish speakers:\", len(fin_speakers))\n",
    "print(\"Danish speakers:\", len(dan_speakers))\n",
    "print(\"Turkish speakers:\", len(tur_speakers))\n",
    "print(\"Hungarian speakers:\", len(hun_speakers))\n",
    "print(\"Portuguese speakers:\", len(por_speakers))\n",
    "print(\"Russian speakers:\", len(rus_speakers))\n",
    "print(\"Maltese speakers:\", len(mlt_speakers))\n",
    "print(\"Latvian speakers:\", len(lav_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to use English\n",
    "#Use Korean, Finnish, Turkish\n",
    "#Danish, Portuguese, Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of speakers\n",
    "def get_tagged_utterances(tokens, speakers): \n",
    "    utterances = []\n",
    "    for conversation in tokens.keys():\n",
    "        for pair in tokens[conversation]:\n",
    "            if(pair[1] in speakers):\n",
    "                utterances.append(tokens[conversation][pair])\n",
    "                \n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_speech = get_tagged_utterances(VOICE_native_tags, eng_speakers)\n",
    "kor_speech = get_tagged_utterances(VOICE_tags, kor_speakers)\n",
    "fin_speech = get_tagged_utterances(VOICE_tags, fin_speakers)\n",
    "tur_speech = get_tagged_utterances(VOICE_tags, tur_speakers)\n",
    "dan_speech = get_tagged_utterances(VOICE_tags, dan_speakers)\n",
    "por_speech = get_tagged_utterances(VOICE_tags, por_speakers)\n",
    "pol_speech = get_tagged_utterances(VOICE_tags, pol_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pairs(li):\n",
    "    tokens = []\n",
    "    for u in li:\n",
    "        for w in u:\n",
    "            tokens.append(w)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSome tags to get rid of: BR(breathing), PA(pause), UH(interjections and hesitations), UNI(unintelligible), UNK(unknown)\\nhttps://www.univie.ac.at/voice/page/documents/VOICE_tagging_manual.pdf\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Some tags to get rid of: BR(breathing), PA(pause), UH(interjections and hesitations), UNI(unintelligible), UNK(unknown)\n",
    "https://www.univie.ac.at/voice/page/documents/VOICE_tagging_manual.pdf\n",
    "\"\"\"   \n",
    "def remove_tags(li):\n",
    "    unwanted_tags = [\"BRfBR\", \"PAfPA\", \"UHfUH\", \"UNIfUNI\", \"UNKfNN\", \"LAfLA\", \"XXfXX\"]\n",
    "    return [pair for pair in li if pair[1] not in unwanted_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(li):\n",
    "    return[pair[1] for pair in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_toks = get_pairs(eng_speech)\n",
    "eng_toks = remove_tags(eng_toks)\n",
    "eng_tags = get_tags(eng_toks)\n",
    "\n",
    "kor_toks = get_pairs(kor_speech)\n",
    "kor_toks = remove_tags(kor_toks)\n",
    "kor_tags = get_tags(kor_toks)\n",
    "\n",
    "fin_toks = get_pairs(fin_speech)\n",
    "fin_toks = remove_tags(fin_toks)\n",
    "fin_tags = get_tags(fin_toks)\n",
    "\n",
    "tur_toks = get_pairs(tur_speech)\n",
    "tur_toks = remove_tags(tur_toks)\n",
    "tur_tags = get_tags(tur_toks)\n",
    "\n",
    "dan_toks = get_pairs(dan_speech)\n",
    "dan_toks = remove_tags(dan_toks)\n",
    "dan_tags = get_tags(dan_toks)\n",
    "\n",
    "por_toks = get_pairs(por_speech)\n",
    "por_toks = remove_tags(por_toks)\n",
    "por_tags = get_tags(por_toks)\n",
    "\n",
    "pol_toks = get_pairs(pol_speech)\n",
    "pol_toks = remove_tags(pol_toks)\n",
    "pol_tags = get_tags(pol_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trigrams(li):\n",
    "    trigram_list = []\n",
    "    for trigram in list(nltk.trigrams(li)):\n",
    "        if len(trigram) > 0:\n",
    "            trigram_list.append(trigram)\n",
    "            \n",
    "    return trigram_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_tag_trigrams = get_trigrams(eng_tags)\n",
    "kor_tag_trigrams = get_trigrams(kor_tags)\n",
    "fin_tag_trigrams = get_trigrams(fin_tags)\n",
    "tur_tag_trigrams = get_trigrams(tur_tags)\n",
    "dan_tag_trigrams = get_trigrams(dan_tags)\n",
    "por_tag_trigrams = get_trigrams(por_tags)\n",
    "pol_tag_trigrams = get_trigrams(pol_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47990"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_tag_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_freq = nltk.FreqDist(eng_tag_trigrams)\n",
    "kor_freq = nltk.FreqDist(kor_tag_trigrams)\n",
    "fin_freq = nltk.FreqDist(fin_tag_trigrams)\n",
    "tur_freq = nltk.FreqDist(tur_tag_trigrams)\n",
    "dan_freq = nltk.FreqDist(dan_tag_trigrams)\n",
    "por_freq = nltk.FreqDist(por_tag_trigrams)\n",
    "pol_freq = nltk.FreqDist(pol_tag_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent part-of-speech trigrams for each L1 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Polish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(REfRE, REfRE, REfRE)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(INfIN, DTfDT, NNfNN)</td>\n",
       "      <td>(REfRE, REfRE, REfRE)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(REfRE, REfRE, REfRE)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(REfRE, REfRE, REfRE)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(DTfDT, NNfNN, INfIN)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(REfRE, REfRE, REfRE)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(NNfNN, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNfNN)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "      <td>(FWfFW, FWfFW, FWfFW)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(INfIN, DTfDT, JJfJJ)</td>\n",
       "      <td>(TOfTO, VVfVV, DTfDT)</td>\n",
       "      <td>(TOfTO, VVfVV, DTfDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(PPfPP, MDfMD, VVfVV)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(CDfCD, CDfCD, CDfCD)</td>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "      <td>(DTfDT, JJfJJ, NNSfNNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(PPfPP, VVPfVVP, PPfPP)</td>\n",
       "      <td>(PPfPP, VVPfVVP, PPfPP)</td>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "      <td>(NNfNN, NNfNN, INfIN)</td>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(NNfNN, INfIN, PPfPP)</td>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(JJfJJ, NNfNN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(INfIN, INfIN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(NNfNN, REfRE, REfRE)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(NNSfNNS, INfIN, DTfDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(PPfPP, VBSfVBS, RBfRB)</td>\n",
       "      <td>(PPfPP, VVPfVVP, PPfPP)</td>\n",
       "      <td>(NNfNN, NNfNN, NNfNN)</td>\n",
       "      <td>(VVfVV, INfIN, DTfDT)</td>\n",
       "      <td>(NNSfNNS, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(INfIN, INfIN, DTfDT)</td>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "      <td>(RBfRB, INfIN, DTfDT)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, INfIN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, PPfPP)</td>\n",
       "      <td>(DTfDT, NNSfNNS, INfIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(RBfRB, INfIN, DTfDT)</td>\n",
       "      <td>(PPfPP, VVPfVVP, INfIN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, RBfRB)</td>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "      <td>(INfIN, PPfPP, VVPfVVP)</td>\n",
       "      <td>(DTfDT, NNfNN, PPfPP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(INfIN, PPfPP, VVPfVVP)</td>\n",
       "      <td>(PPfPP, VBPfVBP, VVGfVVG)</td>\n",
       "      <td>(NNfNN, INfIN, NNfNN)</td>\n",
       "      <td>(DTfDT, NNfNN, PPfPP)</td>\n",
       "      <td>(VVfVV, DTfDT, NNfNN)</td>\n",
       "      <td>(PPfPP, VVPfVVP, INfIN)</td>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(INfIN, DTfDT, NNSfNNS)</td>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "      <td>(NNSfNNS, INfIN, DTfDT)</td>\n",
       "      <td>(TOfTO, VVfVV, DTfDT)</td>\n",
       "      <td>(NNfNN, NNfNN, INfIN)</td>\n",
       "      <td>(VVfVV, DTfDT, NNfNN)</td>\n",
       "      <td>(INfIN, JJfJJ, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(PPfPP, MDfMD, RBfRB)</td>\n",
       "      <td>(TOfTO, VVfVV, INfIN)</td>\n",
       "      <td>(INfIN, INfIN, DTfDT)</td>\n",
       "      <td>(NNfNN, INfIN, NPfNP)</td>\n",
       "      <td>(MDfMD, VVfVV, INfIN)</td>\n",
       "      <td>(RBfRB, RBfRB, RBfRB)</td>\n",
       "      <td>(VVfVV, DTfDT, NNfNN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(DTfDT, NNfNN, CCfCC)</td>\n",
       "      <td>(INfIN, PPfPP, VVPfVVP)</td>\n",
       "      <td>(INfIN, PPfPP, VVPfVVP)</td>\n",
       "      <td>(NNfNN, INfIN, PPfPP)</td>\n",
       "      <td>(VVPfVVP, RBfRB, VVfVV)</td>\n",
       "      <td>(DTfDT, NNfNN, NNfNN)</td>\n",
       "      <td>(NNfNN, INfIN, JJfJJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(NNfNN, INfIN, INfIN)</td>\n",
       "      <td>(DTfDT, NNfNN, PPfPP)</td>\n",
       "      <td>(PPfPP, VBSfVBS, RBfRB)</td>\n",
       "      <td>(REfRE, REfRE, PPfPP)</td>\n",
       "      <td>(NNSfNNS, INfIN, DTfDT)</td>\n",
       "      <td>(DTfDT, NNfNN, PPfPP)</td>\n",
       "      <td>(JJfJJ, NNSfNNS, INfIN)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1=Danish                 L1=English  \\\n",
       "0     (INfIN, DTfDT, NNfNN)      (INfIN, DTfDT, NNfNN)   \n",
       "1     (DTfDT, NNfNN, INfIN)      (DTfDT, NNfNN, INfIN)   \n",
       "2     (DTfDT, JJfJJ, NNfNN)      (DTfDT, JJfJJ, NNfNN)   \n",
       "3     (REfRE, REfRE, REfRE)      (NNfNN, INfIN, DTfDT)   \n",
       "4     (NNfNN, INfIN, DTfDT)      (REfRE, REfRE, REfRE)   \n",
       "5     (INfIN, DTfDT, JJfJJ)      (PPfPP, MDfMD, VVfVV)   \n",
       "6     (JJfJJ, NNfNN, INfIN)      (INfIN, DTfDT, JJfJJ)   \n",
       "7     (PPfPP, MDfMD, VVfVV)      (NNfNN, INfIN, NNfNN)   \n",
       "8     (DTfDT, NNfNN, NNfNN)      (JJfJJ, NNfNN, INfIN)   \n",
       "9   (PPfPP, VVPfVVP, PPfPP)    (PPfPP, VVPfVVP, PPfPP)   \n",
       "10    (NNfNN, INfIN, PPfPP)    (PPfPP, VVPfVVP, RBfRB)   \n",
       "11    (INfIN, INfIN, INfIN)      (DTfDT, NNfNN, NNfNN)   \n",
       "12    (NNfNN, INfIN, NNfNN)    (PPfPP, VBSfVBS, RBfRB)   \n",
       "13    (INfIN, INfIN, DTfDT)    (INfIN, DTfDT, NNSfNNS)   \n",
       "14  (PPfPP, VVPfVVP, RBfRB)      (RBfRB, INfIN, DTfDT)   \n",
       "15  (INfIN, PPfPP, VVPfVVP)  (PPfPP, VBPfVBP, VVGfVVG)   \n",
       "16  (INfIN, DTfDT, NNSfNNS)      (DTfDT, NNfNN, CCfCC)   \n",
       "17    (PPfPP, MDfMD, RBfRB)      (TOfTO, VVfVV, INfIN)   \n",
       "18    (DTfDT, NNfNN, CCfCC)    (INfIN, PPfPP, VVPfVVP)   \n",
       "19    (NNfNN, INfIN, INfIN)      (DTfDT, NNfNN, PPfPP)   \n",
       "\n",
       "                 L1=Finnish                L1=Korean                L1=Polish  \\\n",
       "0     (INfIN, DTfDT, NNfNN)    (REfRE, REfRE, REfRE)    (INfIN, DTfDT, NNfNN)   \n",
       "1     (DTfDT, NNfNN, INfIN)    (INfIN, DTfDT, NNfNN)    (REfRE, REfRE, REfRE)   \n",
       "2     (REfRE, REfRE, REfRE)    (DTfDT, JJfJJ, NNfNN)    (DTfDT, NNfNN, INfIN)   \n",
       "3     (DTfDT, JJfJJ, NNfNN)    (DTfDT, NNfNN, INfIN)    (NNfNN, INfIN, DTfDT)   \n",
       "4     (NNfNN, INfIN, DTfDT)    (NNfNN, INfIN, DTfDT)    (DTfDT, JJfJJ, NNfNN)   \n",
       "5     (INfIN, DTfDT, JJfJJ)    (FWfFW, FWfFW, FWfFW)    (PPfPP, MDfMD, VVfVV)   \n",
       "6     (PPfPP, MDfMD, VVfVV)    (PPfPP, MDfMD, VVfVV)    (INfIN, DTfDT, JJfJJ)   \n",
       "7     (JJfJJ, NNfNN, INfIN)    (DTfDT, NNfNN, NNfNN)    (DTfDT, NNfNN, NNfNN)   \n",
       "8   (PPfPP, VVPfVVP, RBfRB)    (CDfCD, CDfCD, CDfCD)  (PPfPP, VVPfVVP, RBfRB)   \n",
       "9   (INfIN, DTfDT, NNSfNNS)    (NNfNN, NNfNN, INfIN)  (INfIN, DTfDT, NNSfNNS)   \n",
       "10    (DTfDT, NNfNN, CCfCC)    (JJfJJ, NNfNN, INfIN)    (JJfJJ, NNfNN, INfIN)   \n",
       "11    (DTfDT, NNfNN, NNfNN)    (NNfNN, REfRE, REfRE)    (NNfNN, INfIN, NNfNN)   \n",
       "12  (PPfPP, VVPfVVP, PPfPP)    (NNfNN, NNfNN, NNfNN)    (VVfVV, INfIN, DTfDT)   \n",
       "13    (RBfRB, INfIN, DTfDT)    (NNfNN, INfIN, NNfNN)  (PPfPP, VVPfVVP, INfIN)   \n",
       "14  (PPfPP, VVPfVVP, INfIN)  (PPfPP, VVPfVVP, RBfRB)    (DTfDT, NNfNN, CCfCC)   \n",
       "15    (NNfNN, INfIN, NNfNN)    (DTfDT, NNfNN, PPfPP)    (VVfVV, DTfDT, NNfNN)   \n",
       "16  (NNSfNNS, INfIN, DTfDT)    (TOfTO, VVfVV, DTfDT)    (NNfNN, NNfNN, INfIN)   \n",
       "17    (INfIN, INfIN, DTfDT)    (NNfNN, INfIN, NPfNP)    (MDfMD, VVfVV, INfIN)   \n",
       "18  (INfIN, PPfPP, VVPfVVP)    (NNfNN, INfIN, PPfPP)  (VVPfVVP, RBfRB, VVfVV)   \n",
       "19  (PPfPP, VBSfVBS, RBfRB)    (REfRE, REfRE, PPfPP)  (NNSfNNS, INfIN, DTfDT)   \n",
       "\n",
       "              L1=Portuguese               L1=Turkish  \n",
       "0     (INfIN, DTfDT, NNfNN)    (INfIN, DTfDT, NNfNN)  \n",
       "1     (DTfDT, NNfNN, INfIN)    (DTfDT, NNfNN, INfIN)  \n",
       "2     (NNfNN, INfIN, DTfDT)    (DTfDT, JJfJJ, NNfNN)  \n",
       "3     (DTfDT, JJfJJ, NNfNN)    (NNfNN, INfIN, DTfDT)  \n",
       "4     (PPfPP, MDfMD, VVfVV)    (INfIN, DTfDT, JJfJJ)  \n",
       "5     (INfIN, DTfDT, JJfJJ)    (JJfJJ, NNfNN, INfIN)  \n",
       "6     (TOfTO, VVfVV, DTfDT)    (TOfTO, VVfVV, DTfDT)  \n",
       "7   (PPfPP, VVPfVVP, RBfRB)    (PPfPP, MDfMD, VVfVV)  \n",
       "8   (INfIN, DTfDT, NNSfNNS)  (DTfDT, JJfJJ, NNSfNNS)  \n",
       "9     (JJfJJ, NNfNN, INfIN)    (DTfDT, NNfNN, CCfCC)  \n",
       "10    (DTfDT, NNfNN, CCfCC)    (NNfNN, INfIN, NNfNN)  \n",
       "11    (NNfNN, INfIN, NNfNN)  (NNSfNNS, INfIN, DTfDT)  \n",
       "12  (NNSfNNS, INfIN, DTfDT)    (DTfDT, NNfNN, NNfNN)  \n",
       "13  (PPfPP, VVPfVVP, PPfPP)  (DTfDT, NNSfNNS, INfIN)  \n",
       "14  (INfIN, PPfPP, VVPfVVP)    (DTfDT, NNfNN, PPfPP)  \n",
       "15  (PPfPP, VVPfVVP, INfIN)  (INfIN, DTfDT, NNSfNNS)  \n",
       "16    (VVfVV, DTfDT, NNfNN)    (INfIN, JJfJJ, NNfNN)  \n",
       "17    (RBfRB, RBfRB, RBfRB)    (VVfVV, DTfDT, NNfNN)  \n",
       "18    (DTfDT, NNfNN, NNfNN)    (NNfNN, INfIN, JJfJJ)  \n",
       "19    (DTfDT, NNfNN, PPfPP)  (JJfJJ, NNSfNNS, INfIN)  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_df = pd.DataFrame(\n",
    "    {\"L1=English\": [t[0] for t in eng_freq.most_common(20)],\n",
    "     \"L1=Korean\": [t[0] for t in kor_freq.most_common(20)],\n",
    "     \"L1=Finnish\": [t[0] for t in fin_freq.most_common(20)],\n",
    "     \"L1=Turkish\": [t[0] for t in tur_freq.most_common(20)],\n",
    "     \"L1=Danish\": [t[0] for t in dan_freq.most_common(20)],\n",
    "     \"L1=Portuguese\": [t[0] for t in por_freq.most_common(20)],\n",
    "     \"L1=Polish\": [t[0] for t in pol_freq.most_common(20)]\n",
    "    }\n",
    ")\n",
    "\n",
    "trigram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common part-of-speech trigrams in Engish. Compare with these frequencies with other L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Polish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(INfIN, DTfDT, NNfNN)</th>\n",
       "      <td>0.0149823</td>\n",
       "      <td>0.0156791</td>\n",
       "      <td>0.0155236</td>\n",
       "      <td>0.0107851</td>\n",
       "      <td>0.0193401</td>\n",
       "      <td>0.0175261</td>\n",
       "      <td>0.0199672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(DTfDT, NNfNN, INfIN)</th>\n",
       "      <td>0.0120859</td>\n",
       "      <td>0.0138714</td>\n",
       "      <td>0.0124894</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.0115941</td>\n",
       "      <td>0.0148972</td>\n",
       "      <td>0.0153654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(DTfDT, JJfJJ, NNfNN)</th>\n",
       "      <td>0.00937695</td>\n",
       "      <td>0.0122731</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.00897753</td>\n",
       "      <td>0.00918593</td>\n",
       "      <td>0.0100438</td>\n",
       "      <td>0.0135715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(NNfNN, INfIN, DTfDT)</th>\n",
       "      <td>0.00762659</td>\n",
       "      <td>0.00920957</td>\n",
       "      <td>0.0101609</td>\n",
       "      <td>0.0066277</td>\n",
       "      <td>0.0103528</td>\n",
       "      <td>0.0101786</td>\n",
       "      <td>0.0116996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(REfRE, REfRE, REfRE)</th>\n",
       "      <td>0.00760575</td>\n",
       "      <td>0.0116452</td>\n",
       "      <td>0.0120308</td>\n",
       "      <td>0.0204856</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.00194993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PPfPP, MDfMD, VVfVV)</th>\n",
       "      <td>0.00562617</td>\n",
       "      <td>0.00477604</td>\n",
       "      <td>0.00490404</td>\n",
       "      <td>0.00560342</td>\n",
       "      <td>0.00769632</td>\n",
       "      <td>0.00795416</td>\n",
       "      <td>0.0053038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(INfIN, DTfDT, JJfJJ)</th>\n",
       "      <td>0.00479267</td>\n",
       "      <td>0.0067169</td>\n",
       "      <td>0.00687976</td>\n",
       "      <td>0.00289209</td>\n",
       "      <td>0.00640532</td>\n",
       "      <td>0.00640377</td>\n",
       "      <td>0.00904766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(NNfNN, INfIN, NNfNN)</th>\n",
       "      <td>0.00425089</td>\n",
       "      <td>0.00355824</td>\n",
       "      <td>0.0033164</td>\n",
       "      <td>0.00373561</td>\n",
       "      <td>0.00397229</td>\n",
       "      <td>0.00471857</td>\n",
       "      <td>0.00452383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(JJfJJ, NNfNN, INfIN)</th>\n",
       "      <td>0.00420921</td>\n",
       "      <td>0.0063744</td>\n",
       "      <td>0.00483347</td>\n",
       "      <td>0.00451889</td>\n",
       "      <td>0.00402195</td>\n",
       "      <td>0.00532524</td>\n",
       "      <td>0.00748772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PPfPP, VVPfVVP, PPfPP)</th>\n",
       "      <td>0.00406335</td>\n",
       "      <td>0.00422423</td>\n",
       "      <td>0.00381033</td>\n",
       "      <td>0.00265108</td>\n",
       "      <td>0.00206063</td>\n",
       "      <td>0.00444894</td>\n",
       "      <td>0.00249591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PPfPP, VVPfVVP, RBfRB)</th>\n",
       "      <td>0.00391748</td>\n",
       "      <td>0.00348213</td>\n",
       "      <td>0.00472763</td>\n",
       "      <td>0.00355486</td>\n",
       "      <td>0.00427022</td>\n",
       "      <td>0.00572969</td>\n",
       "      <td>0.00319788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(DTfDT, NNfNN, NNfNN)</th>\n",
       "      <td>0.00387581</td>\n",
       "      <td>0.00475701</td>\n",
       "      <td>0.00402202</td>\n",
       "      <td>0.00536241</td>\n",
       "      <td>0.00486606</td>\n",
       "      <td>0.00357263</td>\n",
       "      <td>0.00413384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PPfPP, VBSfVBS, RBfRB)</th>\n",
       "      <td>0.00387581</td>\n",
       "      <td>0.00270198</td>\n",
       "      <td>0.00310471</td>\n",
       "      <td>0.00216907</td>\n",
       "      <td>0.00258199</td>\n",
       "      <td>0.0024941</td>\n",
       "      <td>0.00233991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(INfIN, DTfDT, NNSfNNS)</th>\n",
       "      <td>0.00366743</td>\n",
       "      <td>0.00344408</td>\n",
       "      <td>0.00426898</td>\n",
       "      <td>0.00114479</td>\n",
       "      <td>0.00404677</td>\n",
       "      <td>0.00572969</td>\n",
       "      <td>0.00366586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(RBfRB, INfIN, DTfDT)</th>\n",
       "      <td>0.00329235</td>\n",
       "      <td>0.00274004</td>\n",
       "      <td>0.00377505</td>\n",
       "      <td>0.0015063</td>\n",
       "      <td>0.00273095</td>\n",
       "      <td>0.00296596</td>\n",
       "      <td>0.00296389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         L1=English   L1=Danish  L1=Finnish   L1=Korean  \\\n",
       "(INfIN, DTfDT, NNfNN)     0.0149823   0.0156791   0.0155236   0.0107851   \n",
       "(DTfDT, NNfNN, INfIN)     0.0120859   0.0138714   0.0124894    0.008134   \n",
       "(DTfDT, JJfJJ, NNfNN)    0.00937695   0.0122731    0.011184  0.00897753   \n",
       "(NNfNN, INfIN, DTfDT)    0.00762659  0.00920957   0.0101609   0.0066277   \n",
       "(REfRE, REfRE, REfRE)    0.00760575   0.0116452   0.0120308   0.0204856   \n",
       "(PPfPP, MDfMD, VVfVV)    0.00562617  0.00477604  0.00490404  0.00560342   \n",
       "(INfIN, DTfDT, JJfJJ)    0.00479267   0.0067169  0.00687976  0.00289209   \n",
       "(NNfNN, INfIN, NNfNN)    0.00425089  0.00355824   0.0033164  0.00373561   \n",
       "(JJfJJ, NNfNN, INfIN)    0.00420921   0.0063744  0.00483347  0.00451889   \n",
       "(PPfPP, VVPfVVP, PPfPP)  0.00406335  0.00422423  0.00381033  0.00265108   \n",
       "(PPfPP, VVPfVVP, RBfRB)  0.00391748  0.00348213  0.00472763  0.00355486   \n",
       "(DTfDT, NNfNN, NNfNN)    0.00387581  0.00475701  0.00402202  0.00536241   \n",
       "(PPfPP, VBSfVBS, RBfRB)  0.00387581  0.00270198  0.00310471  0.00216907   \n",
       "(INfIN, DTfDT, NNSfNNS)  0.00366743  0.00344408  0.00426898  0.00114479   \n",
       "(RBfRB, INfIN, DTfDT)    0.00329235  0.00274004  0.00377505   0.0015063   \n",
       "\n",
       "                          L1=Polish L1=Portuguese  L1=Turkish  \n",
       "(INfIN, DTfDT, NNfNN)     0.0193401     0.0175261   0.0199672  \n",
       "(DTfDT, NNfNN, INfIN)     0.0115941     0.0148972   0.0153654  \n",
       "(DTfDT, JJfJJ, NNfNN)    0.00918593     0.0100438   0.0135715  \n",
       "(NNfNN, INfIN, DTfDT)     0.0103528     0.0101786   0.0116996  \n",
       "(REfRE, REfRE, REfRE)      0.012612      0.003303  0.00194993  \n",
       "(PPfPP, MDfMD, VVfVV)    0.00769632    0.00795416   0.0053038  \n",
       "(INfIN, DTfDT, JJfJJ)    0.00640532    0.00640377  0.00904766  \n",
       "(NNfNN, INfIN, NNfNN)    0.00397229    0.00471857  0.00452383  \n",
       "(JJfJJ, NNfNN, INfIN)    0.00402195    0.00532524  0.00748772  \n",
       "(PPfPP, VVPfVVP, PPfPP)  0.00206063    0.00444894  0.00249591  \n",
       "(PPfPP, VVPfVVP, RBfRB)  0.00427022    0.00572969  0.00319788  \n",
       "(DTfDT, NNfNN, NNfNN)    0.00486606    0.00357263  0.00413384  \n",
       "(PPfPP, VBSfVBS, RBfRB)  0.00258199     0.0024941  0.00233991  \n",
       "(INfIN, DTfDT, NNSfNNS)  0.00404677    0.00572969  0.00366586  \n",
       "(RBfRB, INfIN, DTfDT)    0.00273095    0.00296596  0.00296389  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_top_trigrams = [t[0] for t in eng_freq.most_common(15)]\n",
    "\n",
    "eng_trigrams_df = pd.DataFrame(index=eng_top_trigrams, columns = [\"L1=English\", \"L1=Danish\", \"L1=Finnish\", \"L1=Korean\", \"L1=Polish\", \"L1=Portuguese\", \"L1=Turkish\"])\n",
    "\n",
    "for trigram in eng_top_trigrams:\n",
    "    eng_trigrams_df[\"L1=English\"][trigram]= eng_freq[trigram]/len(eng_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Danish\"][trigram]= dan_freq[trigram]/len(dan_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Finnish\"][trigram]= fin_freq[trigram]/len(fin_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Korean\"][trigram]= kor_freq[trigram]/len(kor_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Polish\"][trigram]= pol_freq[trigram]/len(pol_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Portuguese\"][trigram]= por_freq[trigram]/len(por_tag_trigrams)\n",
    "    eng_trigrams_df[\"L1=Turkish\"][trigram]= tur_freq[trigram]/len(tur_tag_trigrams)\n",
    "    \n",
    "eng_trigrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('INfIN', 'DTfDT', 'NNfNN'), 719),\n",
       " (('DTfDT', 'NNfNN', 'INfIN'), 580),\n",
       " (('DTfDT', 'JJfJJ', 'NNfNN'), 450),\n",
       " (('NNfNN', 'INfIN', 'DTfDT'), 366),\n",
       " (('REfRE', 'REfRE', 'REfRE'), 365),\n",
       " (('PPfPP', 'MDfMD', 'VVfVV'), 270),\n",
       " (('INfIN', 'DTfDT', 'JJfJJ'), 230),\n",
       " (('NNfNN', 'INfIN', 'NNfNN'), 204),\n",
       " (('JJfJJ', 'NNfNN', 'INfIN'), 202),\n",
       " (('PPfPP', 'VVPfVVP', 'PPfPP'), 195),\n",
       " (('PPfPP', 'VVPfVVP', 'RBfRB'), 188),\n",
       " (('DTfDT', 'NNfNN', 'NNfNN'), 186),\n",
       " (('PPfPP', 'VBSfVBS', 'RBfRB'), 186),\n",
       " (('INfIN', 'DTfDT', 'NNSfNNS'), 176),\n",
       " (('RBfRB', 'INfIN', 'DTfDT'), 158),\n",
       " (('PPfPP', 'VBPfVBP', 'VVGfVVG'), 157),\n",
       " (('DTfDT', 'NNfNN', 'CCfCC'), 154),\n",
       " (('TOfTO', 'VVfVV', 'INfIN'), 151),\n",
       " (('INfIN', 'PPfPP', 'VVPfVVP'), 148),\n",
       " (('DTfDT', 'NNfNN', 'PPfPP'), 144)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_trigram_df = {}\n",
    "eng_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get native speaker trigram outliers (in terms of frequency vs. other L1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_common = {}\n",
    "less_common = {}\n",
    "\n",
    "for trigram in eng_freq:\n",
    "    #trigram = trigram[0]\n",
    "    \n",
    "    avg = 0\n",
    "    avg = avg + (kor_freq[trigram] / len(kor_tag_trigrams))\n",
    "    avg = avg + (fin_freq[trigram] / len(fin_tag_trigrams))\n",
    "    avg = avg + (tur_freq[trigram] / len(tur_tag_trigrams))\n",
    "    avg = avg + (dan_freq[trigram] / len(dan_tag_trigrams))\n",
    "    avg = avg + (por_freq[trigram] / len(por_tag_trigrams))\n",
    "    avg = avg + (pol_freq[trigram] / len(pol_tag_trigrams))\n",
    "    \n",
    "    avg /= 6\n",
    "    \n",
    "    eng_percent = (eng_freq[trigram] / len(eng_tag_trigrams))\n",
    "    if eng_percent > (avg * 2) and eng_freq[trigram] > 5:\n",
    "        more_common[trigram] = eng_freq[trigram]\n",
    "        \n",
    "        \n",
    "    if eng_percent < (avg * 0.5) and eng_freq[trigram] > 5:\n",
    "        less_common[trigram] = eng_freq[trigram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native trigram outliers -- more frequent that other L1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PPfPP', 'VHPfVHP', 'VVNfVVN')\n",
      "\tEnglish: 0.002208793498645551\n",
      "\tFinnish: 0.00091730172170477\n",
      "\tKorean: 0.0006627703801891908\n",
      "\tTurkish: 0.0006239762889010217\n",
      "\tDanish: 0.0012748791718993797\n",
      "\tPortuguese: 0.0006066734074823053\n",
      "\tPolish: 0.001390302639092331\n",
      "('PPfPP', 'VBDfVBD', 'VVGfVVG')\n",
      "\tEnglish: 0.0013752865180245884\n",
      "\tFinnish: 0.0003175275190516511\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0004186170415191993\n",
      "\tPortuguese: 0.0013481631277384564\n",
      "\tPolish: 0.0004965366568186896\n",
      "('VBPfVBP', 'VVGfVVG', 'INfIN')\n",
      "\tEnglish: 0.0013336111689935403\n",
      "\tFinnish: 0.0009525825571549535\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.0007019733250136495\n",
      "\tDanish: 0.0006088975149370171\n",
      "\tPortuguese: 0.0009437141894169194\n",
      "\tPolish: 0.0007199781523870999\n",
      "('DTfDT', 'VBSfVBS', 'RBfRB')\n",
      "\tEnglish: 0.0010418837257762034\n",
      "\tFinnish: 0.0007056167090036692\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 7.799703611262772e-05\n",
      "\tDanish: 0.000799177988354835\n",
      "\tPortuguese: 0.0\n",
      "\tPolish: 0.0003972293254549517\n",
      "('PREfPRE', 'PPfPP', 'VVPfVVP')\n",
      "\tEnglish: 0.0007709939570743905\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.0\n",
      "\tTurkish: 0.00023399110833788317\n",
      "\tDanish: 0.00032347680481029036\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.0002730951612502793\n",
      "('VBSfVBS', 'RBfRB', 'DTfDT')\n",
      "\tEnglish: 0.0007501562825588665\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0005137572782281082\n",
      "\tPortuguese: 0.00020222446916076846\n",
      "\tPolish: 0.00019861466272747585\n",
      "('VBDfVBD', 'VVGfVVG', 'INfIN')\n",
      "\tEnglish: 0.0006459679099812461\n",
      "\tFinnish: 0.00010584250635055038\n",
      "\tKorean: 6.0251852744471894e-05\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.00011416828405069072\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.00017378782988654139\n",
      "('INfIN', 'WPfWP', 'PPfPP')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.0001764041772509173\n",
      "\tKorean: 0.00012050370548894379\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.0006659816569623625\n",
      "\tPortuguese: 0.0004718570947084597\n",
      "\tPolish: 0.00019861466272747585\n",
      "('INfIN', 'PPfPP', 'REfRE')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.00021168501270110075\n",
      "\tKorean: 0.00036151111646683137\n",
      "\tTurkish: 0.00015599407222525544\n",
      "\tDanish: 0.00030444875746850857\n",
      "\tPortuguese: 0.0002696326255476913\n",
      "\tPolish: 0.00022344149556841034\n",
      "('NNSfNNS', 'PREfPRE', 'VVPfVVP')\n",
      "\tEnglish: 0.000604292560950198\n",
      "\tFinnish: 0.0002469658481512842\n",
      "\tKorean: 0.00018075555823341568\n",
      "\tTurkish: 7.799703611262772e-05\n",
      "\tDanish: 0.00020930852075959965\n",
      "\tPortuguese: 0.0004044489383215369\n",
      "\tPolish: 0.0002482683284093448\n"
     ]
    }
   ],
   "source": [
    "for trigram in sorted(more_common, key=more_common.get, reverse=True)[:10]:\n",
    "    print(trigram)\n",
    "    \n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native trigram outliers -- less frequent that other L1s. (Maybe try this again, but excluding pause and hesitation tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PPfPP', 'VHPfVHP', 'DTfDT')\n",
      "\tEnglish: 0.0006876432590122942\n",
      "\tFinnish: 0.0010231442280553204\n",
      "\tKorean: 0.0014460444658673255\n",
      "\tTurkish: 0.001403946650027299\n",
      "\tDanish: 0.0018266925448110515\n",
      "\tPortuguese: 0.0019548365352207615\n",
      "\tPolish: 0.0008192854837508379\n",
      "('PPfPP', 'PPfPP', 'PPfPP')\n",
      "\tEnglish: 0.0004584288393415295\n",
      "\tFinnish: 0.000458650860852385\n",
      "\tKorean: 0.0007230222329336627\n",
      "\tTurkish: 0.00023399110833788317\n",
      "\tDanish: 0.001788636450127488\n",
      "\tPortuguese: 0.0018874283788338389\n",
      "\tPolish: 0.0005710171553414931\n",
      "('NPfNP', 'CCfCC', 'NPfNP')\n",
      "\tEnglish: 0.0004375911648260054\n",
      "\tFinnish: 0.0005644933672029354\n",
      "\tKorean: 0.0025908296680122915\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.0005137572782281082\n",
      "\tPortuguese: 0.0010785305021907652\n",
      "\tPolish: 0.0005958439881824276\n",
      "('CCfCC', 'DTfDT', 'JJfJJ')\n",
      "\tEnglish: 0.0003959158157949573\n",
      "\tFinnish: 0.0011289867344058708\n",
      "\tKorean: 0.00030125926372235944\n",
      "\tTurkish: 0.001949925902815693\n",
      "\tDanish: 0.0007611218936712714\n",
      "\tPortuguese: 0.0009437141894169194\n",
      "\tPolish: 0.0004468829911368207\n",
      "('DTfDT', 'NPfNP', 'NNfNN')\n",
      "\tEnglish: 0.00037507814127943324\n",
      "\tFinnish: 0.0006703358735534857\n",
      "\tKorean: 0.0008435259384226065\n",
      "\tTurkish: 0.000545979252788394\n",
      "\tDanish: 0.001617384024051452\n",
      "\tPortuguese: 0.0004718570947084597\n",
      "\tPolish: 0.0007448049852280344\n",
      "('RBfRB', 'PPfPP', 'VHPfVHP')\n",
      "\tEnglish: 0.00037507814127943324\n",
      "\tFinnish: 0.0005644933672029354\n",
      "\tKorean: 0.0007832740856781347\n",
      "\tTurkish: 0.0010139614694641603\n",
      "\tDanish: 0.0008182060356966168\n",
      "\tPortuguese: 0.0005392652510953826\n",
      "\tPolish: 0.0008192854837508379\n",
      "('NPfNP', 'CCfCC', 'PPfPP')\n",
      "\tEnglish: 0.0003542404667639091\n",
      "\tFinnish: 0.0003880891899520181\n",
      "\tKorean: 0.0009037777911670784\n",
      "\tTurkish: 0.0006239762889010217\n",
      "\tDanish: 0.000799177988354835\n",
      "\tPortuguese: 0.0008088978766430738\n",
      "\tPolish: 0.0007696318180689689\n",
      "('EXfEX', 'VBZfVBZ', 'DTfDT')\n",
      "\tEnglish: 0.0003542404667639091\n",
      "\tFinnish: 0.0005292125317527519\n",
      "\tKorean: 0.00048201482195577515\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.00053278532556989\n",
      "\tPortuguese: 0.0006740815638692282\n",
      "\tPolish: 0.0011420343106829862\n",
      "('CDfCD', 'CDfCD', 'CDfCD')\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 0.00010584250635055038\n",
      "\tKorean: 0.00475989636681328\n",
      "\tTurkish: 0.0012479525778020435\n",
      "\tDanish: 0.000266392662784945\n",
      "\tPortuguese: 0.0008088978766430738\n",
      "\tPolish: 0.0010179001464783138\n",
      "('FWfFW', 'FWfFW', 'FWfFW')\n",
      "\tEnglish: 0.00033340279224838506\n",
      "\tFinnish: 3.528083545018346e-05\n",
      "\tKorean: 0.006266192685425077\n",
      "\tTurkish: 0.0\n",
      "\tDanish: 0.0008182060356966168\n",
      "\tPortuguese: 6.740815638692282e-05\n",
      "\tPolish: 0.002333722287047841\n"
     ]
    }
   ],
   "source": [
    "for trigram in sorted(less_common, key=less_common.get, reverse=True)[:10]:\n",
    "    print(trigram)\n",
    "    print(\"\\tEnglish: \" + str(eng_freq[trigram] / len(eng_tag_trigrams)))\n",
    "    print(\"\\tFinnish: \" + str(fin_freq[trigram] / len(fin_tag_trigrams)))\n",
    "    print(\"\\tKorean: \" + str(kor_freq[trigram] / len(kor_tag_trigrams)))\n",
    "    print(\"\\tTurkish: \" + str(tur_freq[trigram] / len(tur_tag_trigrams)))\n",
    "    print(\"\\tDanish: \" + str(dan_freq[trigram] / len(dan_tag_trigrams)))\n",
    "    print(\"\\tPortuguese: \" + str(por_freq[trigram] / len(por_tag_trigrams)))\n",
    "    print(\"\\tPolish: \" + str(pol_freq[trigram] / len(pol_tag_trigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing discourse markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discourse_markers(speech):\n",
    "    dm_list = []\n",
    "    markers = [[t for t in u if t[1] == \"DMfDM\"] for u in speech]\n",
    "    for m in markers:\n",
    "        dm_list.extend(m)\n",
    "        \n",
    "    #return dm_list\n",
    "    return dm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_dm = get_discourse_markers(eng_speech)\n",
    "kor_dm = get_discourse_markers(kor_speech)\n",
    "fin_dm = get_discourse_markers(fin_speech)\n",
    "tur_dm = get_discourse_markers(tur_speech)\n",
    "dan_dm = get_discourse_markers(dan_speech)\n",
    "por_dm = get_discourse_markers(por_speech)\n",
    "pol_dm = get_discourse_markers(pol_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dm_percent(speech, dm_list):\n",
    "    total = 0\n",
    "    for u in speech:\n",
    "        total += len(u)\n",
    "    \n",
    "    return len(dm_list)/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of discourse markers across L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.01287</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.017388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.014251   0.013229    0.012288    0.010293   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions    0.01287       0.008287   0.017388  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "dm_df['L1=English'] = get_dm_percent(eng_speech, eng_dm)\n",
    "dm_df['L1=Korean'] = get_dm_percent(kor_speech, kor_dm)\n",
    "dm_df['L1=Finnish'] = get_dm_percent(fin_speech, fin_dm)\n",
    "dm_df['L1=Turkish'] = get_dm_percent(tur_speech, tur_dm)\n",
    "dm_df['L1=Danish'] = get_dm_percent(dan_speech, dan_dm)\n",
    "dm_df['L1=Portuguese'] = get_dm_percent(por_speech, por_dm)\n",
    "dm_df['L1=Polish'] = get_dm_percent(pol_speech, pol_dm)\n",
    "\n",
    "dm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_dm_words = [dm[0].replace('\\n', '') for dm in eng_dm]\n",
    "kor_dm_words = [dm[0].replace('\\n', '') for dm in kor_dm]\n",
    "fin_dm_words = [dm[0].replace('\\n', '') for dm in fin_dm]\n",
    "tur_dm_words = [dm[0].replace('\\n', '') for dm in tur_dm]\n",
    "dan_dm_words = [dm[0].replace('\\n', '') for dm in dan_dm]\n",
    "por_dm_words = [dm[0].replace('\\n', '') for dm in por_dm]\n",
    "pol_dm_words = [dm[0].replace('\\n', '') for dm in pol_dm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 202,\n",
       "          'look': 1,\n",
       "          'right': 50,\n",
       "          'so': 419,\n",
       "          'well': 116,\n",
       "          'whatever': 13})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dm_freqs = nltk.FreqDist(eng_dm_words)\n",
    "eng_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 55, 'right': 33, 'so': 174, 'well': 27, 'whatever': 4})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_dm_freqs = nltk.FreqDist(kor_dm_words)\n",
    "kor_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 111, 'right': 10, 'so': 226, 'well': 72, 'whatever': 8})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_dm_freqs = nltk.FreqDist(fin_dm_words)\n",
    "fin_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 16, 'right': 15, 'so': 119, 'well': 13, 'whatever': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_dm_freqs = nltk.FreqDist(tur_dm_words)\n",
    "tur_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 125, 'right': 30, 'so': 499, 'well': 137, 'whatever': 16})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dan_dm_freqs = nltk.FreqDist(dan_dm_words)\n",
    "dan_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.01287</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.017388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.014251   0.013229    0.012288    0.010293   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions    0.01287       0.008287   0.017388  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_dm_freqs = nltk.FreqDist(por_dm_words)\n",
    "dm_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "dm_df['L1=English'] = get_dm_percent(eng_speech, eng_dm)\n",
    "dm_df['L1=Korean'] = get_dm_percent(kor_speech, kor_dm)\n",
    "dm_df['L1=Finnish'] = get_dm_percent(fin_speech, fin_dm)\n",
    "dm_df['L1=Turkish'] = get_dm_percent(tur_speech, tur_dm)\n",
    "dm_df['L1=Danish'] = get_dm_percent(dan_speech, dan_dm)\n",
    "dm_df['L1=Portuguese'] = get_dm_percent(por_speech, por_dm)\n",
    "dm_df['L1=Polish'] = get_dm_percent(pol_speech, pol_dm)\n",
    "\n",
    "dm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 265,\n",
       "          'look': 1,\n",
       "          'right': 40,\n",
       "          'so': 450,\n",
       "          'well': 66,\n",
       "          'whatever': 28})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_dm_freqs = nltk.FreqDist(pol_dm_words)\n",
    "pol_dm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>so</th>\n",
       "      <td>0.523096</td>\n",
       "      <td>0.593857</td>\n",
       "      <td>0.529274</td>\n",
       "      <td>0.72561</td>\n",
       "      <td>0.61834</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.252185</td>\n",
       "      <td>0.187713</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.154895</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.311765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>0.144819</td>\n",
       "      <td>0.0921502</td>\n",
       "      <td>0.168618</td>\n",
       "      <td>0.0792683</td>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.0980392</td>\n",
       "      <td>0.0776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.062422</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>0.0234192</td>\n",
       "      <td>0.0914634</td>\n",
       "      <td>0.0371747</td>\n",
       "      <td>0.0196078</td>\n",
       "      <td>0.0470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatever</th>\n",
       "      <td>0.0162297</td>\n",
       "      <td>0.0136519</td>\n",
       "      <td>0.0187354</td>\n",
       "      <td>0.00609756</td>\n",
       "      <td>0.0198265</td>\n",
       "      <td>0.0196078</td>\n",
       "      <td>0.0329412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>0.00124844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00117647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L1=English  L1=Korean L1=Finnish  L1=Turkish  L1=Danish  \\\n",
       "so          0.523096   0.593857   0.529274     0.72561    0.61834   \n",
       "like        0.252185   0.187713   0.259953    0.097561   0.154895   \n",
       "well        0.144819  0.0921502   0.168618   0.0792683   0.169765   \n",
       "right       0.062422   0.112628  0.0234192   0.0914634  0.0371747   \n",
       "whatever   0.0162297  0.0136519  0.0187354  0.00609756  0.0198265   \n",
       "look      0.00124844          0          0           0          0   \n",
       "\n",
       "         L1=Portuguese   L1=Polish  \n",
       "so            0.745098    0.529412  \n",
       "like          0.117647    0.311765  \n",
       "well         0.0980392   0.0776471  \n",
       "right        0.0196078   0.0470588  \n",
       "whatever     0.0196078   0.0329412  \n",
       "look                 0  0.00117647  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourse_markers = eng_dm_freqs.most_common()\n",
    "discourse_markers = [b[0] for b in discourse_markers]\n",
    "\n",
    "dm_words_df = pd.DataFrame(index = discourse_markers, columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "for word in discourse_markers:\n",
    "    dm_words_df['L1=English'][word] = eng_dm_freqs[word]/sum(eng_dm_freqs.values())\n",
    "    dm_words_df['L1=Korean'][word] = kor_dm_freqs[word]/sum(kor_dm_freqs.values())\n",
    "    dm_words_df['L1=Finnish'][word] = fin_dm_freqs[word]/sum(fin_dm_freqs.values())\n",
    "    dm_words_df['L1=Turkish'][word] = tur_dm_freqs[word]/sum(tur_dm_freqs.values())\n",
    "    dm_words_df['L1=Danish'][word] = dan_dm_freqs[word]/sum(dan_dm_freqs.values())\n",
    "    dm_words_df['L1=Portuguese'][word] = por_dm_freqs[word]/sum(por_dm_freqs.values())\n",
    "    dm_words_df['L1=Polish'][word] = pol_dm_freqs[word]/sum(pol_dm_freqs.values())\n",
    "    \n",
    "dm_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting distribution of specific discourse markers across specific L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_count(speech):\n",
    "    total = 0\n",
    "    for u in speech:\n",
    "        total += len(u)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so\n",
      "\tEnglish: 0.5230961298377028\n",
      "\tFinnish: 0.5292740046838408\n",
      "\tKorean: 0.5938566552901023\n",
      "\tTurkish: 0.725609756097561\n",
      "\tDanish: 0.6183395291201983\n",
      "\tPortuguese: 0.7450980392156863\n",
      "\tPolish: 0.5294117647058824\n",
      "well\n",
      "\tEnglish: 0.14481897627965043\n",
      "\tFinnish: 0.1686182669789227\n",
      "\tKorean: 0.09215017064846416\n",
      "\tTurkish: 0.07926829268292683\n",
      "\tDanish: 0.1697645600991326\n",
      "\tPortuguese: 0.09803921568627451\n",
      "\tPolish: 0.07764705882352942\n",
      "like\n",
      "\tEnglish: 0.25218476903870163\n",
      "\tFinnish: 0.25995316159250587\n",
      "\tKorean: 0.18771331058020477\n",
      "\tTurkish: 0.0975609756097561\n",
      "\tDanish: 0.15489467162329615\n",
      "\tPortuguese: 0.11764705882352941\n",
      "\tPolish: 0.31176470588235294\n",
      "right\n",
      "\tEnglish: 0.062421972534332085\n",
      "\tFinnish: 0.0234192037470726\n",
      "\tKorean: 0.11262798634812286\n",
      "\tTurkish: 0.09146341463414634\n",
      "\tDanish: 0.03717472118959108\n",
      "\tPortuguese: 0.0196078431372549\n",
      "\tPolish: 0.047058823529411764\n",
      "whatever\n",
      "\tEnglish: 0.016229712858926344\n",
      "\tFinnish: 0.01873536299765808\n",
      "\tKorean: 0.013651877133105802\n",
      "\tTurkish: 0.006097560975609756\n",
      "\tDanish: 0.01982651796778191\n",
      "\tPortuguese: 0.0196078431372549\n",
      "\tPolish: 0.03294117647058824\n",
      "look\n",
      "\tEnglish: 0.0012484394506866417\n",
      "\tFinnish: 0.0\n",
      "\tKorean: 0.0\n",
      "\tTurkish: 0.0\n",
      "\tDanish: 0.0\n",
      "\tPortuguese: 0.0\n",
      "\tPolish: 0.001176470588235294\n"
     ]
    }
   ],
   "source": [
    "for dm in eng_dm_freqs:\n",
    "    print(dm)\n",
    "    print(\"\\tEnglish: \" + str(eng_dm_freqs[dm] / len(eng_dm_words)))\n",
    "    print(\"\\tFinnish: \" + str(fin_dm_freqs[dm] / len(fin_dm_words)))\n",
    "    print(\"\\tKorean: \" + str(kor_dm_freqs[dm] / len(kor_dm_words)))\n",
    "    print(\"\\tTurkish: \" + str(tur_dm_freqs[dm] / len(tur_dm_words)))\n",
    "    print(\"\\tDanish: \" + str(dan_dm_freqs[dm] / len(dan_dm_words)))\n",
    "    print(\"\\tPortuguese: \" + str(por_dm_freqs[dm] / len(por_dm_words)))\n",
    "    print(\"\\tPolish: \" + str(pol_dm_freqs[dm] / len(pol_dm_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Article/Determiner Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eng_speech -- (word, tag) tupes\n",
    "#eng_tags -- list of tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_words(li):\n",
    "    count = 0\n",
    "    for u in li:\n",
    "        count += len(u)\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determiner_words(li):\n",
    "    words = []\n",
    "    \n",
    "    for utterance in li:\n",
    "        for pair in utterance:\n",
    "            if pair[1] == \"DTfDT\":\n",
    "                words.append(pair[0].replace(\"\\n\", \"\"))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>determiner proportions</th>\n",
       "      <td>0.092807</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.106683</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>0.094908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        L1=English  L1=Korean  L1=Finnish  L1=Turkish  \\\n",
       "determiner proportions    0.092807   0.085427    0.107176    0.106683   \n",
       "\n",
       "                        L1=Danish  L1=Portuguese  L1=Polish  \n",
       "determiner proportions   0.106743       0.107973   0.094908  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_df = pd.DataFrame(index = ['determiner proportions'], columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "eng_dets = determiner_words(eng_speech)\n",
    "kor_dets = determiner_words(kor_speech)\n",
    "fin_dets = determiner_words(fin_speech)\n",
    "tur_dets = determiner_words(tur_speech)\n",
    "dan_dets = determiner_words(dan_speech)\n",
    "por_dets = determiner_words(por_speech)\n",
    "pol_dets = determiner_words(pol_speech)\n",
    "\n",
    "det_df['L1=English'] = len(eng_dets)/len(eng_toks)\n",
    "det_df['L1=Korean'] = len(kor_dets)/len(kor_toks)\n",
    "det_df['L1=Finnish'] = len(fin_dets)/len(fin_toks)\n",
    "det_df['L1=Turkish'] = len(tur_dets)/len(tur_toks)\n",
    "det_df['L1=Danish'] = len(dan_dets)/len(dan_toks)\n",
    "det_df['L1=Portuguese'] = len(por_dets)/len(por_toks)\n",
    "det_df['L1=Polish'] = len(pol_dets)/len(pol_toks)\n",
    "\n",
    "det_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing specfic determiner words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_det_words = nltk.FreqDist(eng_dets)\n",
    "kor_det_words = nltk.FreqDist(kor_dets)\n",
    "fin_det_words = nltk.FreqDist(fin_dets)\n",
    "tur_det_words = nltk.FreqDist(tur_dets)\n",
    "dan_det_words = nltk.FreqDist(dan_dets)\n",
    "por_det_words = nltk.FreqDist(por_dets)\n",
    "pol_det_words = nltk.FreqDist(pol_dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1=English</th>\n",
       "      <th>L1=Korean</th>\n",
       "      <th>L1=Finnish</th>\n",
       "      <th>L1=Turkish</th>\n",
       "      <th>L1=Danish</th>\n",
       "      <th>L1=Portuguese</th>\n",
       "      <th>L1=Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0406318</td>\n",
       "      <td>0.0398819</td>\n",
       "      <td>0.0539406</td>\n",
       "      <td>0.0626998</td>\n",
       "      <td>0.0489002</td>\n",
       "      <td>0.0549302</td>\n",
       "      <td>0.0509173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.0178155</td>\n",
       "      <td>0.0127719</td>\n",
       "      <td>0.0151697</td>\n",
       "      <td>0.0140373</td>\n",
       "      <td>0.0213677</td>\n",
       "      <td>0.0163106</td>\n",
       "      <td>0.011668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.0147108</td>\n",
       "      <td>0.0094584</td>\n",
       "      <td>0.0138997</td>\n",
       "      <td>0.0113858</td>\n",
       "      <td>0.0148984</td>\n",
       "      <td>0.00660511</td>\n",
       "      <td>0.00638018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.00683447</td>\n",
       "      <td>0.00885596</td>\n",
       "      <td>0.0102307</td>\n",
       "      <td>0.00600484</td>\n",
       "      <td>0.00808661</td>\n",
       "      <td>0.0137494</td>\n",
       "      <td>0.0140513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>0.00254209</td>\n",
       "      <td>0.00668715</td>\n",
       "      <td>0.00225781</td>\n",
       "      <td>0.00327536</td>\n",
       "      <td>0.0026448</td>\n",
       "      <td>0.00431354</td>\n",
       "      <td>0.00245773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.00245874</td>\n",
       "      <td>0.000421712</td>\n",
       "      <td>0.00201087</td>\n",
       "      <td>0.00116977</td>\n",
       "      <td>0.00323464</td>\n",
       "      <td>0.00155018</td>\n",
       "      <td>0.00109233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.00195866</td>\n",
       "      <td>0.00174709</td>\n",
       "      <td>0.00201087</td>\n",
       "      <td>0.00194962</td>\n",
       "      <td>0.00213106</td>\n",
       "      <td>0.00269596</td>\n",
       "      <td>0.00181227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these</th>\n",
       "      <td>0.0018128</td>\n",
       "      <td>0.000903669</td>\n",
       "      <td>0.00268115</td>\n",
       "      <td>0.0015597</td>\n",
       "      <td>0.00121775</td>\n",
       "      <td>0.00141538</td>\n",
       "      <td>0.000744768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0.000958493</td>\n",
       "      <td>0.00126514</td>\n",
       "      <td>0.00105835</td>\n",
       "      <td>0.00124776</td>\n",
       "      <td>0.000932339</td>\n",
       "      <td>0.00155018</td>\n",
       "      <td>0.00131576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>those</th>\n",
       "      <td>0.000812635</td>\n",
       "      <td>0.000662691</td>\n",
       "      <td>0.00116419</td>\n",
       "      <td>0.00132574</td>\n",
       "      <td>0.00078012</td>\n",
       "      <td>0.00128058</td>\n",
       "      <td>0.00139023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.000770962</td>\n",
       "      <td>0.000481957</td>\n",
       "      <td>0.000458618</td>\n",
       "      <td>0.000389924</td>\n",
       "      <td>0.000799148</td>\n",
       "      <td>0.000943587</td>\n",
       "      <td>0.000546163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0.000666778</td>\n",
       "      <td>0.000903669</td>\n",
       "      <td>0.000917237</td>\n",
       "      <td>0.000623879</td>\n",
       "      <td>0.000951366</td>\n",
       "      <td>0.000943587</td>\n",
       "      <td>0.00084407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>0.000375063</td>\n",
       "      <td>0.000180734</td>\n",
       "      <td>0.000493897</td>\n",
       "      <td>0.000467909</td>\n",
       "      <td>0.000247355</td>\n",
       "      <td>0.000808789</td>\n",
       "      <td>0.00022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>0.000229205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000141113</td>\n",
       "      <td>0</td>\n",
       "      <td>9.51366e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000248256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>both</th>\n",
       "      <td>0.000166694</td>\n",
       "      <td>0.000180734</td>\n",
       "      <td>0.000458618</td>\n",
       "      <td>0.000233955</td>\n",
       "      <td>0.00028541</td>\n",
       "      <td>0.000471793</td>\n",
       "      <td>0.00022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every</th>\n",
       "      <td>6.25104e-05</td>\n",
       "      <td>0.00102416</td>\n",
       "      <td>0.000282227</td>\n",
       "      <td>0.000311939</td>\n",
       "      <td>0.000133191</td>\n",
       "      <td>0.000404394</td>\n",
       "      <td>0.000968198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L1=English    L1=Korean   L1=Finnish   L1=Turkish    L1=Danish  \\\n",
       "the        0.0406318    0.0398819    0.0539406    0.0626998    0.0489002   \n",
       "a          0.0178155    0.0127719    0.0151697    0.0140373    0.0213677   \n",
       "that       0.0147108    0.0094584    0.0138997    0.0113858    0.0148984   \n",
       "this      0.00683447   0.00885596    0.0102307   0.00600484   0.00808661   \n",
       "some      0.00254209   0.00668715   0.00225781   0.00327536    0.0026448   \n",
       "an        0.00245874  0.000421712   0.00201087   0.00116977   0.00323464   \n",
       "all       0.00195866   0.00174709   0.00201087   0.00194962   0.00213106   \n",
       "these      0.0018128  0.000903669   0.00268115    0.0015597   0.00121775   \n",
       "any      0.000958493   0.00126514   0.00105835   0.00124776  0.000932339   \n",
       "those    0.000812635  0.000662691   0.00116419   0.00132574   0.00078012   \n",
       "another  0.000770962  0.000481957  0.000458618  0.000389924  0.000799148   \n",
       "no       0.000666778  0.000903669  0.000917237  0.000623879  0.000951366   \n",
       "each     0.000375063  0.000180734  0.000493897  0.000467909  0.000247355   \n",
       "such     0.000229205            0  0.000141113            0  9.51366e-05   \n",
       "both     0.000166694  0.000180734  0.000458618  0.000233955   0.00028541   \n",
       "every    6.25104e-05   0.00102416  0.000282227  0.000311939  0.000133191   \n",
       "\n",
       "        L1=Portuguese    L1=Polish  \n",
       "the         0.0549302    0.0509173  \n",
       "a           0.0163106     0.011668  \n",
       "that       0.00660511   0.00638018  \n",
       "this        0.0137494    0.0140513  \n",
       "some       0.00431354   0.00245773  \n",
       "an         0.00155018   0.00109233  \n",
       "all        0.00269596   0.00181227  \n",
       "these      0.00141538  0.000744768  \n",
       "any        0.00155018   0.00131576  \n",
       "those      0.00128058   0.00139023  \n",
       "another   0.000943587  0.000546163  \n",
       "no        0.000943587   0.00084407  \n",
       "each      0.000808789   0.00022343  \n",
       "such                0  0.000248256  \n",
       "both      0.000471793   0.00022343  \n",
       "every     0.000404394  0.000968198  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "det_words = eng_det_words.most_common()\n",
    "det_words = [b[0] for b in det_words]\n",
    "\n",
    "det_words_df = pd.DataFrame(index = det_words, columns = ['L1=English', 'L1=Korean', 'L1=Finnish', 'L1=Turkish', 'L1=Danish', 'L1=Portuguese', 'L1=Polish'])\n",
    "\n",
    "for word in det_words:\n",
    "    det_words_df['L1=English'][word] = eng_det_words[word]/len(eng_toks)\n",
    "    det_words_df['L1=Korean'][word] = kor_det_words[word]/len(kor_toks)\n",
    "    det_words_df['L1=Finnish'][word] = fin_det_words[word]/len(fin_toks)\n",
    "    det_words_df['L1=Turkish'][word] = tur_det_words[word]/len(tur_toks)\n",
    "    det_words_df['L1=Danish'][word] = dan_det_words[word]/len(dan_toks)\n",
    "    det_words_df['L1=Portuguese'][word] = por_det_words[word]/len(por_toks)\n",
    "    det_words_df['L1=Polish'][word] = pol_det_words[word]/len(pol_toks)\n",
    "det_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
