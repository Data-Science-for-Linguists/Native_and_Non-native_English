{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_tokenized.p', 'rb')\n",
    "VOICE_toks = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_tagged.p', 'rb')\n",
    "VOICE_tags = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('VOICE_participant_info.p', 'rb')\n",
    "participants = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monolingual_speakers(participant_dict, language):\n",
    "    speakers = []\n",
    "    for p in participant_dict.keys():\n",
    "        L1s = participant_dict[p]['L1']\n",
    "        if(len(L1s) == 1 and language in L1s):\n",
    "            speakers.append(p)\n",
    "            \n",
    "    return speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_speakers = get_monolingual_speakers(participants, 'eng')\n",
    "pol_speakers = get_monolingual_speakers(participants, 'pol')\n",
    "kor_speakers = get_monolingual_speakers(participants, 'kor')\n",
    "fin_speakers = get_monolingual_speakers(participants, 'fin')\n",
    "dan_speakers = get_monolingual_speakers(participants, 'dan')\n",
    "tur_speakers = get_monolingual_speakers(participants, 'tur')\n",
    "hun_speakers = get_monolingual_speakers(participants, 'hun')\n",
    "por_speakers = get_monolingual_speakers(participants, 'por')\n",
    "rus_speakers = get_monolingual_speakers(participants, 'rus')\n",
    "mlt_speakers = get_monolingual_speakers(participants, 'mlt')\n",
    "lav_speakers = get_monolingual_speakers(participants, 'lav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English speakers: 62\n",
      "Polish speakers: 35\n",
      "Korean speakers: 14\n",
      "Finnish speakers: 51\n",
      "Danish speakers: 35\n",
      "Turkish speakers: 14\n",
      "Hungarian speakers: 13\n",
      "Portugese speakers: 21\n",
      "Russian speakers: 22\n",
      "Maltese speakers: 22\n",
      "Latvian speakers: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"English speakers:\", len(eng_speakers))\n",
    "print(\"Polish speakers:\", len(pol_speakers))\n",
    "print(\"Korean speakers:\", len(kor_speakers))\n",
    "print(\"Finnish speakers:\", len(fin_speakers))\n",
    "print(\"Danish speakers:\", len(dan_speakers))\n",
    "print(\"Turkish speakers:\", len(tur_speakers))\n",
    "print(\"Hungarian speakers:\", len(hun_speakers))\n",
    "print(\"Portugese speakers:\", len(por_speakers))\n",
    "print(\"Russian speakers:\", len(rus_speakers))\n",
    "print(\"Maltese speakers:\", len(mlt_speakers))\n",
    "print(\"Latvian speakers:\", len(lav_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to use English\n",
    "#Use Korean, Finnish, Turkish\n",
    "#Danish, Portugese, Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of speakers\n",
    "def get_tagged_utterances(tokens, speakers): \n",
    "    utterances = []\n",
    "    for conversation in tokens.keys():\n",
    "        for pair in tokens[conversation]:\n",
    "            if(pair[0] in speakers):\n",
    "                utterances.append(tokens[conversation][pair])\n",
    "                \n",
    "    return utterances\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_speech = get_tagged_utterances(VOICE_tags, eng_speakers)\n",
    "kor_speech = get_tagged_utterances(VOICE_tags, kor_speakers)\n",
    "fin_speech = get_tagged_utterances(VOICE_tags, fin_speakers)\n",
    "tur_speech = get_tagged_utterances(VOICE_tags, tur_speakers)\n",
    "dan_speech = get_tagged_utterances(VOICE_tags, dan_speakers)\n",
    "por_speech = get_tagged_utterances(VOICE_tags, por_speakers)\n",
    "pol_speech = get_tagged_utterances(VOICE_tags, pol_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_len_dists(tok_list):\n",
    "    len_dict = {}\n",
    "    total = 0\n",
    "    for l in tok_list:\n",
    "        utterance_length = len(l)\n",
    "        \n",
    "        if(utterance_length not in len_dict):\n",
    "            len_dict[utterance_length] = 1\n",
    "        else:\n",
    "            len_dict[utterance_length] += 1\n",
    "            \n",
    "        total += 1\n",
    "            \n",
    "    for l in len_dict.keys():\n",
    "        len_dict[l] = len_dict[l]/total\n",
    "        \n",
    "    return len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_dists(len_dists):\n",
    "    for s in sorted(len_dists, key=len_dists.get, reverse=True)[:10]:\n",
    "        print(\"\\t\" + str(s) + \": \" + str(len_dists[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_lens = get_len_dists(eng_speech)\n",
    "kor_lens = get_len_dists(kor_speech)\n",
    "fin_lens = get_len_dists(fin_speech)\n",
    "tur_lens = get_len_dists(tur_speech)\n",
    "dan_lens = get_len_dists(dan_speech)\n",
    "por_lens = get_len_dists(por_speech)\n",
    "pol_lens = get_len_dists(pol_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n",
      "\t1: 0.272583559168925\n",
      "\t2: 0.0948509485094851\n",
      "\t3: 0.06097560975609756\n",
      "\t4: 0.05984643179765131\n",
      "\t5: 0.04968383017163505\n",
      "\t6: 0.047651309846431796\n",
      "\t7: 0.04245709123757904\n",
      "\t8: 0.037037037037037035\n",
      "\t9: 0.03071364046973803\n",
      "\t10: 0.026196928635953028\n",
      "Korean:\n",
      "\t1: 0.26313813813813813\n",
      "\t2: 0.16554054054054054\n",
      "\t3: 0.08108108108108109\n",
      "\t4: 0.05593093093093093\n",
      "\t6: 0.05067567567567568\n",
      "\t5: 0.04804804804804805\n",
      "\t8: 0.03490990990990991\n",
      "\t7: 0.03303303303303303\n",
      "\t10: 0.02702702702702703\n",
      "\t9: 0.025525525525525526\n",
      "Finnish:\n",
      "\t1: 0.32821368948247076\n",
      "\t2: 0.11619365609348915\n",
      "\t3: 0.06310517529215359\n",
      "\t4: 0.051419031719532556\n",
      "\t5: 0.04040066777963272\n",
      "\t6: 0.038731218697829715\n",
      "\t7: 0.032387312186978295\n",
      "\t9: 0.02904841402337229\n",
      "\t8: 0.02671118530884808\n",
      "\t10: 0.019031719532554257\n",
      "Turkish:\n",
      "\t1: 0.14722222222222223\n",
      "\t2: 0.11388888888888889\n",
      "\t3: 0.05\n",
      "\t4: 0.044444444444444446\n",
      "\t5: 0.041666666666666664\n",
      "\t6: 0.03333333333333333\n",
      "\t8: 0.03333333333333333\n",
      "\t9: 0.030555555555555555\n",
      "\t16: 0.025\n",
      "\t10: 0.022222222222222223\n",
      "Danish:\n",
      "\t1: 0.2712522851919561\n",
      "\t2: 0.10397623400365631\n",
      "\t3: 0.051645338208409504\n",
      "\t4: 0.04181901279707496\n",
      "\t5: 0.04181901279707496\n",
      "\t6: 0.038391224862888484\n",
      "\t7: 0.03610603290676417\n",
      "\t8: 0.029478976234003657\n",
      "\t10: 0.024680073126142597\n",
      "\t9: 0.024680073126142597\n",
      "Portugese:\n",
      "\t1: 0.14596273291925466\n",
      "\t3: 0.07763975155279502\n",
      "\t2: 0.07453416149068323\n",
      "\t4: 0.06935817805383022\n",
      "\t6: 0.06314699792960662\n",
      "\t8: 0.048654244306418216\n",
      "\t7: 0.047619047619047616\n",
      "\t5: 0.045548654244306416\n",
      "\t9: 0.040372670807453416\n",
      "\t10: 0.036231884057971016\n",
      "Polish:\n",
      "\t1: 0.2444962444962445\n",
      "\t2: 0.12794612794612795\n",
      "\t3: 0.07252007252007252\n",
      "\t4: 0.06863506863506863\n",
      "\t5: 0.053613053613053616\n",
      "\t6: 0.045066045066045064\n",
      "\t7: 0.039886039886039885\n",
      "\t8: 0.03781403781403781\n",
      "\t9: 0.027972027972027972\n",
      "\t11: 0.022792022792022793\n"
     ]
    }
   ],
   "source": [
    "print(\"English:\")\n",
    "get_top_dists(eng_lens)\n",
    "print(\"Korean:\")\n",
    "get_top_dists(kor_lens)\n",
    "print(\"Finnish:\")\n",
    "get_top_dists(fin_lens)\n",
    "print(\"Turkish:\")\n",
    "get_top_dists(tur_lens)\n",
    "print(\"Danish:\")\n",
    "get_top_dists(dan_lens)\n",
    "print(\"Portugese:\")\n",
    "get_top_dists(por_lens)\n",
    "print(\"Polish:\")\n",
    "get_top_dists(pol_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Will analyze tags in sentences of a fixed length. Want to pick an utterance length that's common across all L1s\n",
    "# (short utterances are very common in all groups), but want to pick length long enough to get some interesting results\n",
    "\n",
    "#Will try utterances of length 3 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_in_utterance_length(tok_list, utterance_len):\n",
    "    utterances = []\n",
    "    for u in tok_list:\n",
    "        if(len(u) == utterance_len):\n",
    "            tags = [pair[1] for pair in u]\n",
    "            utterances.append(tags)\n",
    "            \n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng3_tags = tags_in_utterance_length(eng_speech, 3)\n",
    "kor3_tags = tags_in_utterance_length(kor_speech, 3)\n",
    "fin3_tags = tags_in_utterance_length(fin_speech, 3)\n",
    "tur3_tags = tags_in_utterance_length(tur_speech, 3)\n",
    "dan3_tags = tags_in_utterance_length(dan_speech, 3)\n",
    "por3_tags = tags_in_utterance_length(por_speech, 3)\n",
    "pol3_tags = tags_in_utterance_length(pol_speech, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng3_tags)\n",
    "len(kor3_tags)\n",
    "len(fin3_tags)\n",
    "len(tur3_tags)\n",
    "len(dan3_tags)\n",
    "len(por3_tags)\n",
    "len(pol3_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
