{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katherine Kairis, kak275@pitt.edu, 12/15/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data for VOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data from the corpus\n",
    "The first step is reading in the contents of each file in the corpus. As the files are read in, two different dictionaries are populated: conversations and participants.  \n",
    "Since the files are in XML format, conversations contains BeautifulSoup objects for each file's contents.  \n",
    "participants contains information(native language, age, occupation, etc.) about every participant in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions: participant_info and conversation_lines\n",
    "* participant_info takes the contents of one conversation and a dictionary containing participants' information. It uses BeautifulSoup commands to get all of the participants listed in the conversation, in addition to the person's native language(s), sex, age, occupation, and role. All of this information is stored in a subdictionary, which are the values of the participants dictionary.  \n",
    "* conversation_lines takes a file path, a single conversation's XML contents, and a dictionary of conversations. The file name is saved in the dictionary as a key, and the XML contents are saved in the dictionary as the file's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes a conversation (in XML format) and a participants dictionary. Gets the participants in the\n",
    "#conversation their information (native language, age, occupation, etc.), and adds them\n",
    "#to the participants dictionary.\n",
    "\n",
    "def participant_info(contents, participants_dict):\n",
    "    #Get all of the participants in the given conversation, and iterate through each person in the list\n",
    "    people = contents.find('listPerson', {'type': 'identified'}).findAll('person')\n",
    "    for p in people:\n",
    "        #info is a subdirectory that contains a single participant's information. The participant's \n",
    "        #id will be added to the participants dictionary, and the info dictionary will be the value\n",
    "        #corresponding to the participant.\n",
    "        info = {}\n",
    "        \n",
    "        name = p['xml:id']\n",
    "        c = name.split(\"_\")[0]\n",
    "        c = c + \".xml\"\n",
    "        \n",
    "        #Get the current spekers's role, age, sex, and the conversation that they participate in.\n",
    "        info['conversation'] = c\n",
    "        info['role'] = p['role']\n",
    "        info['age'] = p.age.get_text()\n",
    "        info['sex'] = p.sex.get_text()\n",
    "        \n",
    "        #In some cases, the occupation isn't listed. If it is included, get the text of the occupation field.\n",
    "        #If it isn't included, \"None\" will be stored as the occupation, since p.occupation returns \"None.\"\n",
    "        try:\n",
    "            info['occupation'] = p.occupation.get_text()\n",
    "        except AttributeError:\n",
    "            info['occupation'] = p.occupation\n",
    "        \n",
    "        #Get a list of the languages that the participant speaks. Iterate through the list, and add them to the\n",
    "        #dictionary according to the speaker's level (ie. L1).\n",
    "        languages = p.findAll('langKnown')\n",
    "        for l in languages:\n",
    "            level = l['level']\n",
    "            language = l['tag']\n",
    "            language = language.split('-')[0]\n",
    "        \n",
    "            if level in info:\n",
    "                info[level].append(language)\n",
    "            else:\n",
    "                info[level] = [language]\n",
    "    \n",
    "        #Get the participant's ID number, and make it a key in the participants dictionary. The value will be\n",
    "        #the info dictionary\n",
    "        participants_dict[name] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes a file's path, its XML contents, and a dictionary. Create a dictionary whose keys are the \n",
    "#file names, and whose values are the files'/conversations' XML contents\n",
    "def conversation_lines(file, contents, conversation_dict):\n",
    "    #Get only the file name from the file's path\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    #Add the file name as a key in the conversation dictionary. Its value is its XML contents\n",
    "    conversation_dict[file_name] = contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and initial processing of the conversation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the XML files containing transcripts of the conversations.\n",
    "#Delete the first file, which is a header file\n",
    "transcripts = glob.glob('data/VOICE/VOICE2.0XML/XML/*.xml')\n",
    "del transcripts[0]\n",
    "\n",
    "tagged_transcripts = glob.glob('data/VOICE/VOICEPOSXML2.0/XML/*.xml')\n",
    "del transcripts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the XML files from the corpus, and process each file as it's read in.\n",
    "conversations = {}\n",
    "participants = {}\n",
    "\n",
    "#For each transcript/conversation in the corpus, get the XML text and the information about the participants\n",
    "for t in transcripts:\n",
    "    #Open the file\n",
    "    file = open(t, 'r')\n",
    "    text = file.read()\n",
    "    xml_contents = BeautifulSoup(text, 'xml')\n",
    "    \n",
    "    #Add the XML contents from the files to the conversations dictionary.\n",
    "    #The dictionary keys are the file names, and their values are the file's XML text.\n",
    "    conversation_lines(t, xml_contents, conversations)\n",
    "    \n",
    "    #Use the participant_info function to get information about the participants in each conversation\n",
    "    #The keys of the dictionary are the participants' ids, and the values are sub-dictionaries\n",
    "    #containing their information.\n",
    "    participant_info(xml_contents, participants)\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of initial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['EDcon4.xml',\n",
       " 'EDcon496.xml',\n",
       " 'EDcon521.xml',\n",
       " 'EDint328.xml',\n",
       " 'EDint330.xml',\n",
       " 'EDint331.xml',\n",
       " 'EDint604.xml',\n",
       " 'EDint605.xml',\n",
       " 'EDsed251.xml',\n",
       " 'EDsed301.xml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 150 conversations in VOICE. \n",
    "#Show the names of the first 10 conversations/files in the conversations dictionary. \n",
    "len(conversations.keys())\n",
    "list(conversations.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<u who=\"#EDsed301_S1\" xml:id=\"EDsed301_u_1\"><unclear> excuse me </unclear> cou- could we talk about the tests<c function=\"rise\" type=\"intonation\"/><pause/></u>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The values in the conversations dictionary are BeautifulSoup objects/XML contents. \n",
    "type(conversations['EDsed301.xml'])\n",
    "\n",
    "#Show an utterance in one of the files/conversations \n",
    "conversations['EDsed301.xml'].find('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['EDcon4_S4',\n",
       " 'EDcon4_S1',\n",
       " 'EDcon4_S2',\n",
       " 'EDcon4_S5',\n",
       " 'EDcon4_S6',\n",
       " 'EDcon4_S7',\n",
       " 'EDcon4_S8',\n",
       " 'EDcon4_S3',\n",
       " 'EDcon4_S9',\n",
       " 'EDcon496_S4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 1253 participants in VOICE corpus.\n",
    "len(participants)\n",
    "\n",
    "#Show the first 10 participants in the participants dictionary\n",
    "list(participants.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1': ['fre'],\n",
       " 'age': '17-24',\n",
       " 'conversation': 'EDsed31.xml',\n",
       " 'occupation': None,\n",
       " 'role': 'student',\n",
       " 'sex': 'female'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'L1': ['nor'],\n",
       " 'age': '35-49',\n",
       " 'conversation': 'POcon549.xml',\n",
       " 'occupation': 'representative of European higher education network',\n",
       " 'role': 'participant',\n",
       " 'sex': 'male'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'L1': ['eng', 'heb', 'dut'],\n",
       " 'age': '17-24',\n",
       " 'conversation': 'EDsed362.xml',\n",
       " 'occupation': 'student',\n",
       " 'role': 'participant',\n",
       " 'sex': 'female'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['eng', 'heb', 'dut']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show some entries (information about the participants) in the participants dictionary\n",
    "participants['EDsed31_S14']\n",
    "participants['POcon549_S11']\n",
    "participants['EDsed362_S14']\n",
    "participants['EDsed362_S14']['L1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and refining the data\n",
    "The first step involves making lists of the native speakers and of the bilingual participants. These lists will be used to ensure that native speakers and bilinguals are not included in the final data. \n",
    "At this point, all of the conversations are in XML format, so BeautifulSoup is used to determine which utterances shouldn't be included in the data because of certain tags (unclear, non-English speech, etc.), and to get the text of the utterances. The text is then used to create dictionaries of tokenized conversations and (word, tag) pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the native speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get native English speakers\n",
    "native_speakers = []\n",
    "\n",
    "#There are multiple ways that English is listed as an L1: \n",
    "#(\"eng\", \"eng-US\", \"eng-CA\", \"eng-GB\", \"eng-GY\", \"eng-AU\", etc)\n",
    "\n",
    "#Use a regular expression to find all of these instances\n",
    "r = re.compile(\"eng.*\")\n",
    "\n",
    "for person in participants:\n",
    "    #returns a list of all languages that contain \"eng.*\" The length of this list should be 1 or 0. If it's 1, the\n",
    "    #participant has English listed as an L1.\n",
    "    english = list(filter(r.match, participants[person]['L1']))\n",
    "    \n",
    "    if len(english) != 0:\n",
    "        #print(person, ':', participants[person])\n",
    "        native_speakers.append(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['EDcon496_S2',\n",
       " 'EDcon521_S1',\n",
       " 'EDint328_S3',\n",
       " 'EDint330_S2',\n",
       " 'EDint330_S4',\n",
       " 'EDsed251_S3',\n",
       " 'EDsed301_S6',\n",
       " 'EDsed362_S1',\n",
       " 'EDsed362_S11',\n",
       " 'EDsed362_S14']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 86 native speakers in the corpus\n",
    "len(native_speakers)\n",
    "\n",
    "#Show the first 10 native speakers in the list\n",
    "native_speakers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1': ['eng'],\n",
       " 'age': '17-24',\n",
       " 'conversation': 'EDsed301.xml',\n",
       " 'occupation': 'student',\n",
       " 'role': 'student',\n",
       " 'sex': 'female'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'L1': ['eng'],\n",
       " 'age': '50+',\n",
       " 'conversation': 'EDsed362.xml',\n",
       " 'occupation': 'professor of history',\n",
       " 'role': 'teacher',\n",
       " 'sex': 'male'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show information about two of the native speakers\n",
    "participants['EDsed301_S6']\n",
    "participants['EDsed362_S1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting bilingual participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bilinguals = []\n",
    "\n",
    "#Iterate through each participant in the participants dictionary.\n",
    "for p in participants:\n",
    "    #Get the participant's L1(s)\n",
    "    languages = participants[p]['L1']\n",
    "    \n",
    "    #If the participant has more than one L1 listed, add them to the list of bilinguals\n",
    "    if len(languages) > 1:\n",
    "        bilinguals.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['EDcon496_S2',\n",
       " 'EDcon521_S1',\n",
       " 'EDint328_S3',\n",
       " 'EDint330_S2',\n",
       " 'EDint330_S4',\n",
       " 'EDint604_S3',\n",
       " 'EDsed251_S3',\n",
       " 'EDsed251_S9',\n",
       " 'EDsed31_S6',\n",
       " 'EDsed362_S11']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 43 bilinguals in the corpus\n",
    "len(bilinguals)\n",
    "\n",
    "#Show the first 10 bilinguals in the list\n",
    "bilinguals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1': ['ger', 'ind'],\n",
       " 'age': '17-24',\n",
       " 'conversation': 'EDsed31.xml',\n",
       " 'occupation': 'student of medicine',\n",
       " 'role': 'student',\n",
       " 'sex': 'male'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants['EDsed31_S6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: valid_utterance\n",
    "The valid_utterance function is used when creating dictionaries for both tokens and (word, tag) pairs. It takes a single utterance, and ensures that it can be included in the data. An utterance cannot be spoken by a native speaker or a bilingual, include non-English or unclear speech, or involve the speaker reading out loud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks to make sure the line can be added to the dictionary.\n",
    "#A line must meet the following criteria: \n",
    "#the speaker cannot be a native speaker of English (not handled in this function)\n",
    "#the speaker cannot be bilingual\n",
    "#the speaker must be listed in the participant directory\n",
    "#the line cannot contain any non-English speech\n",
    "#the line cannot contain any unclear speech\n",
    "#the line cannot contain the speaker reading anything out loud\n",
    "def valid_utterance(participant, line):\n",
    "    if participant in bilinguals:\n",
    "        return False\n",
    "    if participant not in participants:\n",
    "        return False\n",
    "    if line.foreign != None:\n",
    "        return False\n",
    "    if line.unclear != None: \n",
    "        return False\n",
    "    if line.reading_aloud != None:\n",
    "        return False\n",
    "    if line.reading != None :\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary of tokenized conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all of the files in VOICE to create a nested dictionary that contains the word tokens of the\n",
    "#conversations.\n",
    "#The keys of the dictionaries are the file names. The values of these entries are subdictionaries. The keys of the\n",
    "#subdictionary are (line_number, participant) tuples, and the values are lists of tokens.\n",
    "tokenized_conversations = {}\n",
    "conversation_info = {}\n",
    "\n",
    "#Iterate through each conversation's contents\n",
    "for file in conversations:\n",
    "    #Conv_lines contains all of the utterances for the current, single conversation\n",
    "    conv_lines = {}\n",
    "    \n",
    "    #At this point, the contents of the current conversation is still in XML/Beautifuloup, and\n",
    "    #include a lot of extra information.\n",
    "    #In the corpus, lines that are tagged with 'u' indicate an utterance. To get all of the utterances\n",
    "    #in the current file, use find.All('u')\n",
    "    c = conversations[file].findAll('u')\n",
    "    \n",
    "    #Iterate through all of the utterance in the file\n",
    "    for l in c:\n",
    "        #Get the speaker and the id of the current utterance\n",
    "        participant = l['who'].replace(\"#\", \"\")\n",
    "        line_id = l['xml:id']\n",
    "        #Get the text of the current utterance (remove XML tags), and tokenize the utterance using NLTK\n",
    "        text = l.get_text()\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        #If the participant is a native speaker, don't include them in the dictionary of tokenized conversations\n",
    "        if participant in native_speakers:\n",
    "            continue\n",
    "        \n",
    "        #Otherwise, check if the utterance is valid using the valid_utterance function. If it is valid,\n",
    "        #add it to conv_lines. The key is a tuple consisting of (line number, speaker), and the \n",
    "        #value is the tokenized speech.\n",
    "        elif len(text) != 0 and valid_utterance(participant, l) == True:\n",
    "            key = (line_id, participant)\n",
    "            conv_lines[key] = tokens\n",
    "    \n",
    "    #When done iterating through all of the utterances of the current conversation, \n",
    "    #add it to the dictionary of tokenized conversations. The key is the current \n",
    "    #file/conversation, and the value conv_lines.\n",
    "    tokenized_conversations[file] = conv_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 150 conversations\n",
    "len(list(tokenized_conversations.keys()))\n",
    "\n",
    "first_entry = list(tokenized_conversations.keys())[0]\n",
    "first_conversation = tokenized_conversations[first_entry]\n",
    "\n",
    "#There are 671 utterances in the first conversation\n",
    "len(list(first_conversation.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EDcon4_u_2', 'EDcon4_S2'),\n",
       " ('EDcon4_u_3', 'EDcon4_S1'),\n",
       " ('EDcon4_u_4', 'EDcon4_S2'),\n",
       " ('EDcon4_u_5', 'EDcon4_S1'),\n",
       " ('EDcon4_u_6', 'EDcon4_S3'),\n",
       " ('EDcon4_u_7', 'EDcon4_S1'),\n",
       " ('EDcon4_u_9', 'EDcon4_S1'),\n",
       " ('EDcon4_u_11', 'EDcon4_S1'),\n",
       " ('EDcon4_u_12', 'EDcon4_S2'),\n",
       " ('EDcon4_u_13', 'EDcon4_S1')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['and', 'and', 'er']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['oh', 'sorry']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the speaker and line number of the first 10 utterances in the first conversation\n",
    "list(first_conversation.keys())[:10]\n",
    "\n",
    "#Show a few utterances in the first conversation\n",
    "tokenized_conversations[first_entry][('EDcon4_u_5', 'EDcon4_S1')]\n",
    "tokenized_conversations[first_entry][('EDcon4_u_6', 'EDcon4_S3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary of part-of-speech tagged conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the text from the part of speech-tagged files\n",
    "tagged_conv_lines = {}\n",
    "for t in tagged_transcripts:\n",
    "    file = open(t, 'r')\n",
    "    text = file.read()\n",
    "    xml_contents = BeautifulSoup(text, 'xml')\n",
    "    #Use conversation lines to get a dictionary of the XML contents of each conversation\n",
    "    conversation_lines(t, xml_contents, tagged_conv_lines)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate through all of the files in VOICE to a nested dictionary that contains the (word, tag) tuples from the\n",
    "#conversations.\n",
    "#The keys of the dictionaries are the file names. The values of these entries are subdictionaries. The keys of the\n",
    "#subdictionary are (participant, line_number) tuples, and the values are lists of (word, tag) tuples.\n",
    "tagged_conversations = {}\n",
    "tagged_conversations_native = {}\n",
    "\n",
    "#Iterate through each conversation's contents\n",
    "for file in tagged_conv_lines:\n",
    "    #Conv_lines contains all of the utterances for the current, single conversation\n",
    "    conv_lines = {}\n",
    "    #Create a second dictionary for native speakers. It will work the same way as conv_lines\n",
    "    conv_lines_native = {}\n",
    "    \n",
    "    #In the corpus, lines that are tagged with 'u' indicate an utterance. To get all of the utterances\n",
    "    #in the current file, use find.All('u')\n",
    "    c = tagged_conv_lines[file].findAll('u')\n",
    "    \n",
    "    #Iterate through all of the utterances in the file\n",
    "    for l in c:\n",
    "        #Utterance and native_utterance contain the (word,tag) pairs of a single utterance(the \n",
    "        #current one in the iteration)\n",
    "        utterance = []\n",
    "        native_utterance = []\n",
    "        \n",
    "        #Get the speaker and the id of the current utterance\n",
    "        participant = l['who'].replace(\"#\", \"\")\n",
    "        line_id = l['xml:id']\n",
    "        key = (line_id, participant)\n",
    "        \n",
    "        #Check if the current utterance is valid using the valid_utterance function. If it is valid,\n",
    "        #add it to either conv_lines or conv_lines_native.\n",
    "        if valid_utterance(participant, l) == True:  \n",
    "            #In the part-of-speech tagged files, the tag 'w' indicates a word, and includes\n",
    "            #the words part of speech and lemma. To get all of the word, use findall('w')\n",
    "            tags = l.findAll('w')\n",
    "            \n",
    "            #Iterate through all of the words/tags in the utterance\n",
    "            for t in tags:\n",
    "                #Get the word and its part of speech\n",
    "                word = t.text\n",
    "                ana = str(t).split()[1]\n",
    "                ana = ana.split(\"=\")\n",
    "                tag = ana[1][2:]\n",
    "                tag = tag.split('\"')[0]\n",
    "                \n",
    "                #Add the word,tag pair to either native_utterance and conv_lines_native (if the participant\n",
    "                #is in the list of native speakers) or to utterance and conv_lines\n",
    "                if participant in native_speakers:\n",
    "                    native_utterance.append((word, tag))\n",
    "                    conv_lines_native[key] = native_utterance\n",
    "                    \n",
    "                else:\n",
    "                    utterance.append((word, tag))  \n",
    "                    conv_lines[key] = utterance\n",
    "    \n",
    "    #When done iterating through all of the utterances, update both tagged conversations dictionaries\n",
    "    #with the subdictionaries containing tagged utterances from the current conversation\n",
    "    tagged_conversations[file] = conv_lines\n",
    "    tagged_conversations_native[file] = conv_lines_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('EDint328_u_1', 'EDint328_S1'),\n",
       " ('EDint328_u_3', 'EDint328_S2'),\n",
       " ('EDint328_u_4', 'EDint328_S1'),\n",
       " ('EDint328_u_6', 'EDint328_S2'),\n",
       " ('EDint328_u_7', 'EDint328_S1'),\n",
       " ('EDint328_u_8', 'EDint328_S2'),\n",
       " ('EDint328_u_9', 'EDint328_S1'),\n",
       " ('EDint328_u_10', 'EDint328_S1'),\n",
       " ('EDint328_u_12', 'EDint328_S1'),\n",
       " ('EDint328_u_14', 'EDint328_S1')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = list(tagged_conversations.keys())[5]\n",
    "example_conversation = tokenized_conversations[entry]\n",
    "\n",
    "#There are 448 utterances in the example conversation\n",
    "len(list(example_conversation.keys()))\n",
    "\n",
    "#Show the line numbers and speakers of the first 10 utterances in the example conversation\n",
    "list(example_conversation.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 'REfRE'),\n",
       " ('no', 'REfRE'),\n",
       " ('un-', 'XXfXX'),\n",
       " ('unfortunately', 'RBfRB'),\n",
       " ('_1', 'PAfPA'),\n",
       " ('okay', 'REfRE'),\n",
       " ('okay', 'REfRE'),\n",
       " ('_0', 'PAfPA')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('no', 'DTfDT'), ('problem', 'NNfNN'), ('_0', 'PAfPA')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show some tagged utterances in the example conversation\n",
    "tagged_conversations[entry][('EDint328_u_1', 'EDint328_S1')]\n",
    "tagged_conversations[entry][('EDint328_u_10', 'EDint328_S1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the two dictionaries as pickle files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_tokenized.p', 'wb')\n",
    "pickle.dump(tokenized_conversations, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_tagged.p', 'wb')\n",
    "pickle.dump(tagged_conversations, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('VOICE_native_tagged.p', 'wb')\n",
    "pickle.dump(tagged_conversations_native, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"VOICE_participant_info.p\", 'wb')\n",
    "pickle.dump(participants, f, -1)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
